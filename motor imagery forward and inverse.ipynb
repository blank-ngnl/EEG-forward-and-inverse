{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15aa7db",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22bdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs\n",
    "from mne.datasets import fetch_fsaverage\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial import Delaunay\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Dense, Flatten, Concatenate, BatchNormalization, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "%matplotlib inline\n",
    "\n",
    "DIRECTORY_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257a3fa",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45005041",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_mapping = {\n",
    "    \"EEG-Fz\": \"Fz\",\n",
    "    \"EEG-0\": \"FC3\",\n",
    "    \"EEG-1\": \"FC1\",\n",
    "    \"EEG-2\": \"FCz\",\n",
    "    \"EEG-3\": \"FC2\",\n",
    "    \"EEG-4\": \"FC4\",\n",
    "    \"EEG-5\": \"C5\",\n",
    "    \"EEG-C3\": \"C3\", \n",
    "    \"EEG-6\": \"C1\",\n",
    "    \"EEG-Cz\": \"Cz\",\n",
    "    \"EEG-7\": \"C2\",\n",
    "    \"EEG-C4\": \"C4\",\n",
    "    \"EEG-8\": \"C6\",\n",
    "    \"EEG-9\": \"CP3\",\n",
    "    \"EEG-10\": \"CP1\",\n",
    "    \"EEG-11\": \"CPz\",\n",
    "    \"EEG-12\": \"CP2\",\n",
    "    \"EEG-13\": \"CP4\",\n",
    "    \"EEG-14\": \"P1\",\n",
    "    \"EEG-Pz\": \"Pz\",\n",
    "    \"EEG-15\": \"P2\",\n",
    "    \"EEG-16\": \"POz\",\n",
    "    \"EOG-left\": \"EOG-left\",\n",
    "    \"EOG-central\": \"EOG-central\",\n",
    "    \"EOG-right\": \"EOG-right\"\n",
    "}\n",
    "\n",
    "channels_type_mapping = {\n",
    "    \"Fz\": \"eeg\",\n",
    "    \"FC3\": \"eeg\",\n",
    "    \"FC1\": \"eeg\",\n",
    "    \"FCz\": \"eeg\",\n",
    "    \"FC2\": \"eeg\",\n",
    "    \"FC4\": \"eeg\",\n",
    "    \"C5\": \"eeg\",\n",
    "    \"C3\": \"eeg\", \n",
    "    \"C1\": \"eeg\",\n",
    "    \"Cz\": \"eeg\",\n",
    "    \"C2\": \"eeg\",\n",
    "    \"C4\": \"eeg\",\n",
    "    \"C6\": \"eeg\",\n",
    "    \"CP3\": \"eeg\",\n",
    "    \"CP1\": \"eeg\",\n",
    "    \"CPz\": \"eeg\",\n",
    "    \"CP2\": \"eeg\",\n",
    "    \"CP4\": \"eeg\",\n",
    "    \"P1\": \"eeg\",\n",
    "    \"Pz\": \"eeg\",\n",
    "    \"P2\": \"eeg\",\n",
    "    \"POz\": \"eeg\",\n",
    "    \"EOG-left\": \"eog\",\n",
    "    \"EOG-central\": \"eog\",\n",
    "    \"EOG-right\": \"eog\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(\"/Users/ivanl/Downloads/MRIcron_windows/MRIcron/Resources/templates/brodmann.nii.gz\")\n",
    "\n",
    "brodmann_data = img.get_fdata()\n",
    "brodmann_motor = brodmann_data.reshape(-1) == 4\n",
    "print(brodmann_motor)\n",
    "\n",
    "shape, affine = img.shape[:3], img.affine\n",
    "coords = np.array(np.meshgrid(*(range(i) for i in shape), indexing='ij'))\n",
    "coords = np.rollaxis(coords, 0, len(shape) + 1)\n",
    "mm_coords = nib.affines.apply_affine(affine, coords)\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "my_left_points = None\n",
    "my_right_points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "labels utility function\n",
    "\"\"\"\n",
    "def load_subject_labels(name=\"A01E.mat\", dir=\"drive/Shareddrives/Motor Imagery/BCI competition IV dataset/2a/2a true_labels/\"):\n",
    "  data = scipy.io.loadmat(dir + name)[\"classlabel\"].reshape(-1)\n",
    "  return data\n",
    "\n",
    "def load_all_true_labels(dataset_path):\n",
    "  data = {}\n",
    "  for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "      data[file] = load_subject_labels(name=file, dir=root) \n",
    "  return data\n",
    "\n",
    "\"\"\"\n",
    "plot graph utility function\n",
    "\"\"\"\n",
    "def plot_average_graph(subject_name=\"A01T.gdf\", Class=\"left\", filter_channels=None):\n",
    "  average = {\"left\": None, \"right\": None, \"foot\": None, \"tongue\": None, \"unknown\": None}\n",
    "  for event_class, event_data in data[subject_name][\"epoch_data\"].items():\n",
    "    if event_data != []:\n",
    "      average[event_class] = np.transpose(np.mean(event_data, axis=0))\n",
    "\n",
    "  x = average[Class]\n",
    "  if filter_channels is None:\n",
    "    fig, axs = plt.subplots(x.shape[1], gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 21)\n",
    "    for channel in range(x.shape[1]):\n",
    "      axs[channel].title.set_text(ch_names[channel])\n",
    "      axs[channel].title.set_size(20)\n",
    "      axs[channel].title.set_y(0.7)\n",
    "      axs[channel].plot(range(x.shape[0]), x[:, channel])\n",
    "      axs[channel].axvline(x=250, color=\"r\", linestyle='--')\n",
    "      #axs[channel].axvline(x=875, color=\"r\", linestyle='--')\n",
    "  else :\n",
    "    fig, axs = plt.subplots(len(filter_channels), gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 10.5)\n",
    "    for i in range(len(filter_channels)):\n",
    "      for channel in range(x.shape[1]):\n",
    "        if(filter_channels[i] == ch_names[channel]):\n",
    "          axs[i].title.set_text(ch_names[channel])\n",
    "          axs[i].title.set_size(20)\n",
    "          axs[i].title.set_y(0.7)\n",
    "          axs[i].plot(range(x.shape[0]), x[:, channel])\n",
    "          axs[i].axvline(x=250, color=\"r\", linestyle='--')\n",
    "          #axs[i].axvline(x=875, color=\"r\", linestyle='--')\n",
    "          break\n",
    "  plt.tight_layout()\n",
    "\n",
    "def plot_multiple_graph(subject_name=\"A02T.gdf\", classes=[\"left\", \"right\", \"foot\", \"tongue\"], filter_channels=None):\n",
    "  average = {\"left\": None, \"right\": None, \"foot\": None, \"tongue\": None, \"unknown\": None}\n",
    "  for event_class, event_data in data[subject_name][\"epoch_data\"].items():\n",
    "    if event_data != []:\n",
    "      average[event_class] = np.transpose(np.mean(event_data, axis=0))\n",
    "\n",
    "  color = {\"left\": \"b\", \"right\": \"g\", \"foot\": \"c\", \"tongue\": \"m\", \"tongue\": \"y\"}\n",
    "  x = []\n",
    "  for Class in classes:\n",
    "    x.append(average[Class])\n",
    "\n",
    "  if filter_channels is None:\n",
    "    fig, axs = plt.subplots(x[0].shape[1], gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 21)\n",
    "    for channel in range(x[0].shape[1]):\n",
    "      axs[channel].title.set_text(ch_names[channel])\n",
    "      axs[channel].title.set_size(20)\n",
    "      axs[channel].title.set_y(0.7)\n",
    "      axs[channel].axvline(x=250, color=\"r\", linestyle='--')\n",
    "      #axs[channel].axvline(x=875, color=\"r\", linestyle='--')\n",
    "      for i in range(len(classes)):\n",
    "        axs[channel].plot(range(x[i].shape[0]), x[i][:, channel], color=color[classes[i]])\n",
    "  else:\n",
    "    fig, axs = plt.subplots(len(filter_channels), gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 10.5)\n",
    "    for i in range(len(filter_channels)):\n",
    "      for channel in range(x[0].shape[1]):\n",
    "        if(filter_channels[i] == ch_names[channel]):\n",
    "          axs[i].title.set_text(ch_names[channel])\n",
    "          axs[i].title.set_size(20)\n",
    "          axs[i].title.set_y(0.7)\n",
    "          axs[i].axvline(x=250, color=\"r\", linestyle='--')\n",
    "          #axs[i].axvline(x=875, color=\"r\", linestyle='--')\n",
    "          for j in range(len(classes)):\n",
    "            axs[i].plot(range(x[j].shape[0]), x[j][:, channel], color=color[classes[j]])\n",
    "          break\n",
    "  plt.tight_layout()\n",
    "\n",
    "\"\"\"\n",
    "load data function\n",
    "\"\"\"\n",
    "def load_subject(name=\"A01T.gdf\", dir='drive/Shareddrives/Motor Imagery/BCI competition IV dataset/2a/BCICIV_2a_gdf/', debug=None):\n",
    "  subject_data = {}\n",
    "  # Load data\n",
    "  raw = mne.io.read_raw_gdf(dir + name)\n",
    "  # Rename channels\n",
    "  raw.rename_channels(channels_mapping)\n",
    "  # Set channels types\n",
    "  raw.set_channel_types(channels_type_mapping)\n",
    "  # Set montage\n",
    "  # Read and set the EEG electrode locations\n",
    "  ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "  raw.set_montage(ten_twenty_montage)\n",
    "  # Set common average reference\n",
    "  raw.set_eeg_reference('average', projection=True, verbose=False)\n",
    "  # Drop eog channels\n",
    "  raw.drop_channels([\"EOG-left\", \"EOG-central\", \"EOG-right\"])\n",
    "\n",
    "  subject_data[\"raw\"] = raw\n",
    "  subject_data[\"info\"] = raw.info\n",
    "  if debug == \"all\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    for key, item in raw.info.items():\n",
    "      print(key, item)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "  \n",
    "  \"\"\"\n",
    "  '276': 'Idling EEG (eyes open)'\n",
    "  '277': 'Idling EEG (eyes closed)'\n",
    "  '768': 'Start of a trial'\n",
    "  '769': 'Cue onset left (class 1)'\n",
    "  '770': 'Cue onset right (class 2)'\n",
    "  '771': 'Cue onset foot (class 3)'\n",
    "  '772': 'Cue onset tongue (class 4)'\n",
    "  '783': 'Cue unknown'\n",
    "  '1023': 'Rejected trial'\n",
    "  '1072': 'Eye movements'\n",
    "  '32766': 'Start of a new run'\n",
    "  \"\"\"\n",
    "  custom_mapping = {'276': 276, '277': 277, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '783': 783, '1023': 1023, '1072': 1072, '32766': 32766}\n",
    "  events_from_annot, event_dict = mne.events_from_annotations(raw, event_id=custom_mapping)\n",
    "\n",
    "  if debug == \" all\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(event_dict)\n",
    "    print(events_from_annot)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    for i in range(len(raw.annotations)):\n",
    "      print(events_from_annot[i], raw.annotations[i])  \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  class_info = \"Idling EEG (eyes open): \" + str(len(events_from_annot[events_from_annot[:, 2]==276][:, 0])) + \"\\n\" + \\\n",
    "               \"Idling EEG (eyes closed): \" + str(len(events_from_annot[events_from_annot[:, 2]==277][:, 0])) + \"\\n\" + \\\n",
    "               \"Start of a trial: \" + str(len(events_from_annot[events_from_annot[:, 2]==768][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset left (class 1): \" + str(len(events_from_annot[events_from_annot[:, 2]==769][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset right (class 2): \" + str(len(events_from_annot[events_from_annot[:, 2]==770][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset foot (class 3): \" + str(len(events_from_annot[events_from_annot[:, 2]==771][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset tongue (class 4): \" + str(len(events_from_annot[events_from_annot[:, 2]==772][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue unknown: \" + str(len(events_from_annot[events_from_annot[:, 2]==783][:, 0])) + \"\\n\" + \\\n",
    "               \"Rejected trial: \" + str(len(events_from_annot[events_from_annot[:, 2]==1023][:, 0])) + \"\\n\" + \\\n",
    "               \"Eye movements: \" + str(len(events_from_annot[events_from_annot[:, 2]==1072][:, 0])) + \"\\n\" + \\\n",
    "               \"Start of a new run: \" + str(len(events_from_annot[events_from_annot[:, 2]==32766][:, 0]))\n",
    "  subject_data[\"class_info\"] = class_info\n",
    "\n",
    "  if debug == \"all\" or debug == \"important\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(class_info)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  epoch_data = {\"left\": [], \"right\": [], \"foot\": [], \"tongue\": [], \"unknown\": []}\n",
    "  rejected_trial = events_from_annot[events_from_annot[:, 2]==1023][:, 0]\n",
    "  class_dict = {\"left\": 769, \"right\": 770, \"foot\": 771, \"tongue\": 772, \"unknown\": 783}\n",
    "  raw_data = raw.get_data() #(22, 672528)\n",
    "  start = 0                 # cue\n",
    "  stop = 500                # cue+3.0s\n",
    "\n",
    "  for event_class, event_id in class_dict.items():\n",
    "    current_event = events_from_annot[events_from_annot[:, 2]==event_id][:, 0]\n",
    "    if event_class == \"unknown\":\n",
    "      subject_true_labels = true_labels[name[:4]+\".mat\"]\n",
    "      class_dict_labels = {1: \"left\", 2: \"right\", 3: \"foot\", 4: \"tongue\"}\n",
    "      for i in range(len(current_event)):\n",
    "        # exclude artifact\n",
    "        if (current_event[i] - 500 != rejected_trial).all():\n",
    "          current_event_data = np.expand_dims(np.array(raw_data[:22, current_event[i]+start:current_event[i]+stop]), axis=0)\n",
    "          if (epoch_data.get(class_dict_labels[subject_true_labels[i]]) == None).all():\n",
    "            epoch_data[class_dict_labels[subject_true_labels[i]]] = current_event_data\n",
    "          else:\n",
    "            epoch_data[class_dict_labels[subject_true_labels[i]]] = np.append(epoch_data[class_dict_labels[subject_true_labels[i]]], current_event_data, axis=0)\n",
    "    else:\n",
    "      for i in range(len(current_event)):\n",
    "        # exclude artifact\n",
    "        if((current_event[i] - 500 != rejected_trial).all()):\n",
    "          epoch_data[event_class].append(np.array(raw_data[:22, current_event[i]+start:current_event[i]+stop]))\n",
    "      epoch_data[event_class] = np.array(epoch_data[event_class])\n",
    "\n",
    "  if debug == \"all\" or debug == \"important\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    for key, data in epoch_data.items():\n",
    "      print(key, len(data))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  for event_class, event_data in epoch_data.items():\n",
    "    epoch_data[event_class] = np.array(event_data)\n",
    "\n",
    "  subject_data[\"epoch_data\"] = epoch_data\n",
    "    \n",
    "\n",
    "  return subject_data\n",
    "\n",
    "def load_all_subject(dataset_path):\n",
    "  data = {}\n",
    "  for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "      data[file] = load_subject(name=file, dir=root) \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd to google drive\n",
    "os.chdir(\"G:\")\n",
    "\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "subject = 'fsaverage'\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "\n",
    "source = mne.read_source_spaces(src)\n",
    "left = source[0]\n",
    "right = source[1]\n",
    "left_pos = left[\"rr\"][left[\"inuse\"]==1]\n",
    "right_pos = right[\"rr\"][right[\"inuse\"]==1]\n",
    "                        \n",
    "transformation = mne.read_trans(op.join(fs_dir, \"bem\", \"fsaverage-trans.fif\"))\n",
    "\n",
    "save_path = op.join(os.getcwd(), \"Shared drives\", \"Motor Imagery\", \"Source Estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_path = \"Shared drives/Motor Imagery/BCI competition IV dataset/2a/2a true_labels/\"\n",
    "true_labels = load_all_true_labels(true_labels_path)\n",
    "\n",
    "dataset_path = 'Shared drives/Motor Imagery/BCI competition IV dataset/2a/BCICIV_2a_gdf/'\n",
    "data = load_all_subject(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c296e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some information to help to understand functions and data structure\n",
    "\"\"\"\n",
    "for key, item in data.items():\n",
    "  print(key)\n",
    "\n",
    "ch_names = data[\"A01T.gdf\"][\"info\"][\"ch_names\"]\n",
    "print(ch_names)\n",
    "\n",
    "print(data[\"A01T.gdf\"][\"class_info\"])\n",
    "\n",
    "for key, value in data.items():\n",
    "  print(key)\n",
    "  for event_class, event_data in value[\"epoch_data\"].items():\n",
    "      print(event_class, len(event_data))\n",
    "  print()\n",
    "\n",
    "subject_name = \"A01T.gdf\"\n",
    "Class = \"left\"\n",
    "filter_channels = [\"C3\", \"Cz\", \"C4\"]\n",
    "plot_average_graph(subject_name, Class, filter_channels)\n",
    "\n",
    "subject_name = \"A02T.gdf\"\n",
    "classes = [\"left\", \"right\"]\n",
    "filter_channels = [\"C3\", \"Cz\", \"C4\"]\n",
    "plot_multiple_graph(subject_name, classes, filter_channels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs(data):\n",
    "  subjects_data = {}\n",
    "\n",
    "  for subject in data.keys():\n",
    "    epochs_data = {}\n",
    "    for event in data[subject][\"epoch_data\"].keys():\n",
    "      if data[subject][\"epoch_data\"][event].any():\n",
    "        epochs_data[event] = mne.EpochsArray(data[subject][\"epoch_data\"][event], data[subject][\"info\"])\n",
    "    subjects_data[subject] = epochs_data\n",
    "\n",
    "  return subjects_data\n",
    "\n",
    "epochs = create_epochs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_epochs = epochs[\"A01T.gdf\"][\"right\"]\n",
    "my_evoked = my_epochs.average().pick(\"eeg\")\n",
    "\n",
    "noise_cov = mne.compute_covariance(my_epochs, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=False)\n",
    "fwd = mne.make_forward_solution(my_epochs.info, trans=trans, src=src,\n",
    "                            bem=bem, eeg=True, meg=False, mindist=5.0, n_jobs=1)\n",
    "# forward matrix\n",
    "fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                         use_cps=True)\n",
    "\n",
    "inverse_operator = make_inverse_operator(\n",
    "    my_epochs.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
    "\n",
    "method = \"sLORETA\"\n",
    "snr = 3.\n",
    "lambda2 = 1. / snr ** 2\n",
    "stc = mne.minimum_norm.apply_inverse(my_evoked, inverse_operator, lambda2,\n",
    "                              method=method, pick_ori=\"normal\", verbose=True)\n",
    "\n",
    "reconstruct_evoked = mne.apply_forward(fwd_fixed, stc, my_evoked.info)\n",
    "my_evoked.plot_topomap()\n",
    "reconstruct_evoked.plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346696c",
   "metadata": {},
   "source": [
    "# CNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labels\n",
    "left (class 0) right (class 1) foot (class 2) tongue (class 3)\n",
    "\n",
    "channels\n",
    "c3(7) cz(9) c4(11)\n",
    "\"\"\"\n",
    "\n",
    "results = {\"A01\": {}, \"A02\": {}, \"A03\": {}, \"A04\": {}, \"A05\": {}, \"A06\": {}, \"A07\": {}, \"A08\": {}, \"A09\": {}}\n",
    "labels = {\"left\": 0, \"right\": 1}\n",
    "select_channels = [7, 9, 11]\n",
    "debug = True\n",
    "individual = True\n",
    "\n",
    "# train model on each subject individually\n",
    "# data_list = []\n",
    "# if individual:\n",
    "#   for subject in results.keys():\n",
    "#     data_list.append([subject+\"T.gdf\", subject+\"E.gdf\"])\n",
    "# else:\n",
    "#   data_list.append(data.keys())\n",
    "\n",
    "# train model on best two subjects\n",
    "data_list = []\n",
    "data_list.append([\"A03T.gdf\", \"A03E.gdf\", \"A09T.gdf\", \"A09E.gdf\"])\n",
    "\n",
    "for data_name in data_list:\n",
    "  X = None\n",
    "  Y = None\n",
    "  for name in data_name:\n",
    "    for event_class, event_data in data[name][\"epoch_data\"].items():\n",
    "      if event_data.size != 0 and event_class in labels:\n",
    "        data_samples = None\n",
    "        for select_channel in select_channels:\n",
    "          data_sample = np.expand_dims(event_data[:, select_channel, :], axis=1)\n",
    "          if data_samples is not None:\n",
    "            data_samples = np.append(data_samples, data_sample, axis=1)\n",
    "          else:\n",
    "            data_samples = data_sample\n",
    "        event_data = np.array(data_samples)\n",
    "        if X is None:\n",
    "          X = event_data\n",
    "          Y = np.ones(len(event_data), dtype=int) * int(labels[event_class])\n",
    "        else:\n",
    "          X = np.append(X, event_data, axis=0)\n",
    "          Y = np.append(Y, np.ones(len(event_data), dtype=int) * int(labels[event_class]))\n",
    "\n",
    "\n",
    "  Zxx = tf.signal.stft(X, frame_length=256, frame_step=16)\n",
    "  Zxx = tf.abs(Zxx)\n",
    "  Zxx = Zxx.numpy() \n",
    "\n",
    "  if debug:\n",
    "    print(data_name)\n",
    "    print(\"shape of X and Y: \" + str(X.shape) + \" \" + str(Y.shape))\n",
    "    print(\"shape of Zxx: \" + str(Zxx.shape))\n",
    "\n",
    "    #samples = 0\n",
    "    #print(Y[samples])\n",
    "    #log_spec = np.log(Zxx[samples][0].T)\n",
    "    #height = 40\n",
    "    #width = log_spec.shape[1]\n",
    "    #X = np.linspace(0, 2, num=width)\n",
    "    #Y = range(height)\n",
    "    #plt.pcolormesh(X, Y, log_spec[:40, ])\n",
    "    #plt.title('STFT Magnitude')\n",
    "    #plt.ylabel('Frequency [Hz]')\n",
    "    #plt.xlabel('Time [sec]')\n",
    "    #plt.show()\n",
    "\n",
    "  # preprocess data\n",
    "  rgb_weights = [0.2989, 0.5870, 0.1140]\n",
    "  X = None\n",
    "\n",
    "  # spectrogram\n",
    "  left_mean_img = {\"c3\": [], \"cZ\": [], \"c4\": []}\n",
    "  right_mean_img = {\"c3\": [], \"cZ\": [], \"c4\": []}\n",
    "\n",
    "  # convert stft image to numpy array\n",
    "  for i in range(Zxx.shape[0]):\n",
    "    current_image = None\n",
    "    current_data = Zxx[i][:, :, :40]\n",
    "\n",
    "    for channel in range(current_data.shape[0]):\n",
    "      fig = plt.figure(figsize=(16, 40), dpi=1)\n",
    "      plot = fig.add_subplot(111)\n",
    "\n",
    "      log_spec = np.log(current_data[channel].T)\n",
    "      height = log_spec.shape[0]\n",
    "      width = log_spec.shape[1]\n",
    "      x_axis = np.linspace(0, 2, num=width)\n",
    "      y_axis = range(height)\n",
    "      plot.pcolormesh(x_axis, y_axis, log_spec)\n",
    "      plot.axis('off')\n",
    "      fig.tight_layout(pad=0)\n",
    "      fig.canvas.draw()\n",
    "\n",
    "      img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "      img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "      plt.close(fig)\n",
    "      img = np.array(img, dtype=np.float32) / 255\n",
    "\n",
    "      # show rgb image\n",
    "      #my_img = Image.fromarray(np.uint8(img*255))\n",
    "      #display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "\n",
    "      # convert rgb to gray scale\n",
    "      img = np.dot(img[...,:3], rgb_weights)\n",
    "      img = np.expand_dims(img, axis = 2)\n",
    "\n",
    "      if Y[i] == 0:\n",
    "        if channel == 0 :\n",
    "          left_mean_img[\"c3\"].append(img)\n",
    "        elif channel == 1:\n",
    "          left_mean_img[\"cZ\"].append(img)\n",
    "        else:\n",
    "          left_mean_img[\"c4\"].append(img)\n",
    "      else:\n",
    "        if channel == 0 :\n",
    "          right_mean_img[\"c3\"].append(img)\n",
    "        elif channel == 1:\n",
    "          right_mean_img[\"cZ\"].append(img)\n",
    "        else:\n",
    "          right_mean_img[\"c4\"].append(img)\n",
    "\n",
    "      # show grayscale image\n",
    "      #my_img = Image.fromarray(np.uint8(img[:, :, 0]*255), 'L')\n",
    "      #display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "\n",
    "      if current_image is None:\n",
    "        current_image = img\n",
    "      else:\n",
    "        current_image = np.append(current_image, img, axis=1)\n",
    "\n",
    "    current_image = np.expand_dims(current_image, axis=0)\n",
    "\n",
    "    if X is None:\n",
    "      X = current_image\n",
    "    else:\n",
    "      X = np.append(X, current_image, axis=0)\n",
    "\n",
    "  if debug:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    print(\"spectrogram mean\")\n",
    "    left_mean_img_c3 = np.mean(np.array(left_mean_img[\"c3\"]), axis=0)\n",
    "    left_mean_img_cZ = np.mean(np.array(left_mean_img[\"cZ\"]), axis=0)\n",
    "    left_mean_img_c4 = np.mean(np.array(left_mean_img[\"c4\"]), axis=0)\n",
    "    right_mean_img_c3 = np.mean(np.array(right_mean_img[\"c3\"]), axis=0)\n",
    "    right_mean_img_cZ = np.mean(np.array(right_mean_img[\"cZ\"]), axis=0)\n",
    "    right_mean_img_c4 = np.mean(np.array(right_mean_img[\"c4\"]), axis=0)\n",
    "\n",
    "    # show image\n",
    "    \"\"\"\n",
    "    print(\"left_mean_img_c3\")\n",
    "    my_img = Image.fromarray(np.uint8(left_mean_img_c3[:, :, 0]*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"left_mean_img_cZ\")\n",
    "    my_img = Image.fromarray(np.uint8(left_mean_img_cZ[:, :, 0]*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"left_mean_img_c4\")\n",
    "    my_img = Image.fromarray(np.uint8(left_mean_img_c4[:, :, 0]*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"right_mean_img_c3\")\n",
    "    my_img = Image.fromarray(np.uint8(right_mean_img_c3[:, :, 0]*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"right_mean_img_cZ\")\n",
    "    my_img = Image.fromarray(np.uint8(right_mean_img_cZ[:, :, 0]*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"right_mean_img_c4\")\n",
    "    my_img = Image.fromarray(np.uint8(right_mean_img_c4[:, :, 0]*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    \"\"\"\n",
    "    print(\"diff_c3\")\n",
    "    my_img = Image.fromarray(np.uint8(((left_mean_img_c3[:, :, 0]-right_mean_img_c3[:, :, 0])+1)/2*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"diff_cZ\")\n",
    "    my_img = Image.fromarray(np.uint8(((left_mean_img_cZ[:, :, 0]-right_mean_img_cZ[:, :, 0])+1)/2*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "    print(\"diff_c4\")\n",
    "    my_img = Image.fromarray(np.uint8(((left_mean_img_c4[:, :, 0]-right_mean_img_c4[:, :, 0])+1)/2*255), 'L')\n",
    "    display(my_img.resize((16*10, 40*10), PIL.Image.NONE))\n",
    "\n",
    "  class baseline_model(tf.keras.Model):\n",
    "      def __init__(self, channels=22):\n",
    "          super(baseline_model, self).__init__()\n",
    "          self.conv_01 = Conv2D(filters=4, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=\"selu\")\n",
    "          self.batch_norm_01 = BatchNormalization()\n",
    "          self.max_pool_01 = MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding=\"valid\")\n",
    "          self.conv_02 = Conv2D(filters=8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=\"selu\")\n",
    "          self.batch_norm_02 = BatchNormalization()\n",
    "          self.max_pool_02 = MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding=\"valid\")\n",
    "          self.flatten = Flatten()\n",
    "          self.dense_01 = Dense(50, activation=\"selu\")\n",
    "          self.dense_02 = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "      def call(self, inputs):\n",
    "          x = self.conv_01(inputs)\n",
    "          x = self.batch_norm_01(x)\n",
    "          x = self.max_pool_01(x)\n",
    "          x = self.conv_02(x)\n",
    "          x = self.batch_norm_02(x)\n",
    "          x = self.max_pool_02(x)\n",
    "          x = self.flatten(x)\n",
    "          x = self.dense_01(x)\n",
    "          x = self.dense_02(x)\n",
    "          return x\n",
    "\n",
    "  optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "  kfold = 10\n",
    "  accuracy = 0\n",
    "  precision = 0\n",
    "  recall = 0\n",
    "  f1 = 0\n",
    "\n",
    "  skf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "  skf.get_n_splits(X, Y)\n",
    "  for train_index, test_index in skf.split(X, Y):\n",
    "    #print(len(train_index), len(test_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    model = baseline_model()\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    log_dir = DIRECTORY_PATH + \"/logs/\" + data_name[0][:3] + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=200, callbacks=[tensorboard_callback], verbose=0)\n",
    "\n",
    "    Y_hat = model.predict(X_test)\n",
    "    Y_hat = (Y_hat >= 0.5)\n",
    "    #print(\"accuracy: \" + str(accuracy_score(Y_test, Y_hat))) \n",
    "    #print(\"precision:\" + str(precision_score(Y_test, Y_hat, average=\"macro\")))\n",
    "    #print(\"recall:\" + str(recall_score(Y_test, Y_hat, average=\"macro\")))\n",
    "    #print(\"f1:\" + str(f1_score(Y_test, Y_hat, average=\"macro\")))\n",
    "    #print()  \n",
    "    accuracy += accuracy_score(Y_test, Y_hat)\n",
    "    precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "    recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "    f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "\n",
    "  accuracy /= kfold\n",
    "  precision /= kfold\n",
    "  recall /= kfold\n",
    "  f1 /= kfold\n",
    "  if debug:\n",
    "    print(\"accuracy: \" + str(accuracy))\n",
    "    print(\"precision: \" + str(precision))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"f1: \" + str(f1))\n",
    "\n",
    "  results[data_name[0][:3]][\"accuracy\"] = accuracy\n",
    "  results[data_name[0][:3]][\"precision\"] = precision\n",
    "  results[data_name[0][:3]][\"recall\"] = recall\n",
    "  results[data_name[0][:3]][\"f1\"] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average performance\n",
    "average_accuracy = 0\n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_f1 = 0\n",
    "for key, value in results.items():\n",
    "  average_accuracy += value[\"accuracy\"]\n",
    "  average_precision += value[\"precision\"]\n",
    "  average_recall += value[\"recall\"]\n",
    "  average_f1 += value[\"f1\"]\n",
    "\n",
    "average_accuracy /= 9\n",
    "average_precision /= 9\n",
    "average_recall /= 9\n",
    "average_f1 /= 9\n",
    "\n",
    "print(\"average accuracy: \" + str(average_accuracy))\n",
    "print(\"average precision: \" + str(average_precision))\n",
    "print(\"average recall: \" + str(average_recall))\n",
    "print(\"average f1: \" + str(average_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
