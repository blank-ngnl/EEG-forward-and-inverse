{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22bdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs\n",
    "from mne.datasets import fetch_fsaverage\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45005041",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_mapping = {\n",
    "    \"EEG-Fz\": \"Fz\",\n",
    "    \"EEG-0\": \"FC3\",\n",
    "    \"EEG-1\": \"FC1\",\n",
    "    \"EEG-2\": \"FCz\",\n",
    "    \"EEG-3\": \"FC2\",\n",
    "    \"EEG-4\": \"FC4\",\n",
    "    \"EEG-5\": \"C5\",\n",
    "    \"EEG-C3\": \"C3\", \n",
    "    \"EEG-6\": \"C1\",\n",
    "    \"EEG-Cz\": \"Cz\",\n",
    "    \"EEG-7\": \"C2\",\n",
    "    \"EEG-C4\": \"C4\",\n",
    "    \"EEG-8\": \"C6\",\n",
    "    \"EEG-9\": \"CP3\",\n",
    "    \"EEG-10\": \"CP1\",\n",
    "    \"EEG-11\": \"CPz\",\n",
    "    \"EEG-12\": \"CP2\",\n",
    "    \"EEG-13\": \"CP4\",\n",
    "    \"EEG-14\": \"P1\",\n",
    "    \"EEG-Pz\": \"Pz\",\n",
    "    \"EEG-15\": \"P2\",\n",
    "    \"EEG-16\": \"POz\",\n",
    "    \"EOG-left\": \"EOG-left\",\n",
    "    \"EOG-central\": \"EOG-central\",\n",
    "    \"EOG-right\": \"EOG-right\"\n",
    "}\n",
    "\n",
    "channels_type_mapping = {\n",
    "    \"Fz\": \"eeg\",\n",
    "    \"FC3\": \"eeg\",\n",
    "    \"FC1\": \"eeg\",\n",
    "    \"FCz\": \"eeg\",\n",
    "    \"FC2\": \"eeg\",\n",
    "    \"FC4\": \"eeg\",\n",
    "    \"C5\": \"eeg\",\n",
    "    \"C3\": \"eeg\", \n",
    "    \"C1\": \"eeg\",\n",
    "    \"Cz\": \"eeg\",\n",
    "    \"C2\": \"eeg\",\n",
    "    \"C4\": \"eeg\",\n",
    "    \"C6\": \"eeg\",\n",
    "    \"CP3\": \"eeg\",\n",
    "    \"CP1\": \"eeg\",\n",
    "    \"CPz\": \"eeg\",\n",
    "    \"CP2\": \"eeg\",\n",
    "    \"CP4\": \"eeg\",\n",
    "    \"P1\": \"eeg\",\n",
    "    \"Pz\": \"eeg\",\n",
    "    \"P2\": \"eeg\",\n",
    "    \"POz\": \"eeg\",\n",
    "    \"EOG-left\": \"eog\",\n",
    "    \"EOG-central\": \"eog\",\n",
    "    \"EOG-right\": \"eog\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(\"/Users/ivanl/Downloads/MRIcron_windows/MRIcron/Resources/templates/brodmann.nii.gz\")\n",
    "\n",
    "brodmann_data = img.get_fdata()\n",
    "brodmann_motor = brodmann_data.reshape(-1) == 4\n",
    "print(brodmann_motor)\n",
    "\n",
    "shape, affine = img.shape[:3], img.affine\n",
    "coords = np.array(np.meshgrid(*(range(i) for i in shape), indexing='ij'))\n",
    "coords = np.rollaxis(coords, 0, len(shape) + 1)\n",
    "mm_coords = nib.affines.apply_affine(affine, coords)\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "my_left_points = None\n",
    "my_right_points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "labels utility function\n",
    "\"\"\"\n",
    "def load_subject_labels(name=\"A01E.mat\", dir=\"drive/Shareddrives/Motor Imagery/BCI competition IV dataset/2a/2a true_labels/\"):\n",
    "  data = scipy.io.loadmat(dir + name)[\"classlabel\"].reshape(-1)\n",
    "  return data\n",
    "\n",
    "def load_all_true_labels(dataset_path):\n",
    "  data = {}\n",
    "  for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "      data[file] = load_subject_labels(name=file, dir=root) \n",
    "  return data\n",
    "\n",
    "\"\"\"\n",
    "plot graph utility function\n",
    "\"\"\"\n",
    "def plot_average_graph(subject_name=\"A01T.gdf\", Class=\"left\", filter_channels=None):\n",
    "  average = {\"left\": None, \"right\": None, \"foot\": None, \"tongue\": None, \"unknown\": None}\n",
    "  for event_class, event_data in data[subject_name][\"epoch_data\"].items():\n",
    "    if event_data != []:\n",
    "      average[event_class] = np.transpose(np.mean(event_data, axis=0))\n",
    "\n",
    "  x = average[Class]\n",
    "  if filter_channels is None:\n",
    "    fig, axs = plt.subplots(x.shape[1], gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 21)\n",
    "    for channel in range(x.shape[1]):\n",
    "      axs[channel].title.set_text(ch_names[channel])\n",
    "      axs[channel].title.set_size(20)\n",
    "      axs[channel].title.set_y(0.7)\n",
    "      axs[channel].plot(range(x.shape[0]), x[:, channel])\n",
    "      axs[channel].axvline(x=250, color=\"r\", linestyle='--')\n",
    "      #axs[channel].axvline(x=875, color=\"r\", linestyle='--')\n",
    "  else :\n",
    "    fig, axs = plt.subplots(len(filter_channels), gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 10.5)\n",
    "    for i in range(len(filter_channels)):\n",
    "      for channel in range(x.shape[1]):\n",
    "        if(filter_channels[i] == ch_names[channel]):\n",
    "          axs[i].title.set_text(ch_names[channel])\n",
    "          axs[i].title.set_size(20)\n",
    "          axs[i].title.set_y(0.7)\n",
    "          axs[i].plot(range(x.shape[0]), x[:, channel])\n",
    "          axs[i].axvline(x=250, color=\"r\", linestyle='--')\n",
    "          #axs[i].axvline(x=875, color=\"r\", linestyle='--')\n",
    "          break\n",
    "  plt.tight_layout()\n",
    "\n",
    "def plot_multiple_graph(subject_name=\"A02T.gdf\", classes=[\"left\", \"right\", \"foot\", \"tongue\"], filter_channels=None):\n",
    "  average = {\"left\": None, \"right\": None, \"foot\": None, \"tongue\": None, \"unknown\": None}\n",
    "  for event_class, event_data in data[subject_name][\"epoch_data\"].items():\n",
    "    if event_data != []:\n",
    "      average[event_class] = np.transpose(np.mean(event_data, axis=0))\n",
    "\n",
    "  color = {\"left\": \"b\", \"right\": \"g\", \"foot\": \"c\", \"tongue\": \"m\", \"tongue\": \"y\"}\n",
    "  x = []\n",
    "  for Class in classes:\n",
    "    x.append(average[Class])\n",
    "\n",
    "  if filter_channels is None:\n",
    "    fig, axs = plt.subplots(x[0].shape[1], gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 21)\n",
    "    for channel in range(x[0].shape[1]):\n",
    "      axs[channel].title.set_text(ch_names[channel])\n",
    "      axs[channel].title.set_size(20)\n",
    "      axs[channel].title.set_y(0.7)\n",
    "      axs[channel].axvline(x=250, color=\"r\", linestyle='--')\n",
    "      #axs[channel].axvline(x=875, color=\"r\", linestyle='--')\n",
    "      for i in range(len(classes)):\n",
    "        axs[channel].plot(range(x[i].shape[0]), x[i][:, channel], color=color[classes[i]])\n",
    "  else:\n",
    "    fig, axs = plt.subplots(len(filter_channels), gridspec_kw={'hspace': 0})\n",
    "    fig.set_size_inches(37, 10.5)\n",
    "    for i in range(len(filter_channels)):\n",
    "      for channel in range(x[0].shape[1]):\n",
    "        if(filter_channels[i] == ch_names[channel]):\n",
    "          axs[i].title.set_text(ch_names[channel])\n",
    "          axs[i].title.set_size(20)\n",
    "          axs[i].title.set_y(0.7)\n",
    "          axs[i].axvline(x=250, color=\"r\", linestyle='--')\n",
    "          #axs[i].axvline(x=875, color=\"r\", linestyle='--')\n",
    "          for j in range(len(classes)):\n",
    "            axs[i].plot(range(x[j].shape[0]), x[j][:, channel], color=color[classes[j]])\n",
    "          break\n",
    "  plt.tight_layout()\n",
    "\n",
    "\"\"\"\n",
    "load data function\n",
    "\"\"\"\n",
    "def load_subject(name=\"A01T.gdf\", dir='drive/Shareddrives/Motor Imagery/BCI competition IV dataset/2a/BCICIV_2a_gdf/', debug=None):\n",
    "  subject_data = {}\n",
    "  # Load data\n",
    "  raw = mne.io.read_raw_gdf(dir + name)\n",
    "  # Rename channels\n",
    "  raw.rename_channels(channels_mapping)\n",
    "  # Set channels types\n",
    "  raw.set_channel_types(channels_type_mapping)\n",
    "  # Set montage\n",
    "  # Read and set the EEG electrode locations\n",
    "  ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "  raw.set_montage(ten_twenty_montage)\n",
    "  # Set common average reference\n",
    "  raw.set_eeg_reference('average', projection=True, verbose=False)\n",
    "  # Drop eog channels\n",
    "  raw.drop_channels([\"EOG-left\", \"EOG-central\", \"EOG-right\"])\n",
    "\n",
    "  subject_data[\"raw\"] = raw\n",
    "  subject_data[\"info\"] = raw.info\n",
    "  if debug == \"all\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    for key, item in raw.info.items():\n",
    "      print(key, item)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "  \n",
    "  \"\"\"\n",
    "  '276': 'Idling EEG (eyes open)'\n",
    "  '277': 'Idling EEG (eyes closed)'\n",
    "  '768': 'Start of a trial'\n",
    "  '769': 'Cue onset left (class 1)'\n",
    "  '770': 'Cue onset right (class 2)'\n",
    "  '771': 'Cue onset foot (class 3)'\n",
    "  '772': 'Cue onset tongue (class 4)'\n",
    "  '783': 'Cue unknown'\n",
    "  '1023': 'Rejected trial'\n",
    "  '1072': 'Eye movements'\n",
    "  '32766': 'Start of a new run'\n",
    "  \"\"\"\n",
    "  custom_mapping = {'276': 276, '277': 277, '768': 768, '769': 769, '770': 770, '771': 771, '772': 772, '783': 783, '1023': 1023, '1072': 1072, '32766': 32766}\n",
    "  events_from_annot, event_dict = mne.events_from_annotations(raw, event_id=custom_mapping)\n",
    "\n",
    "  if debug == \" all\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(event_dict)\n",
    "    print(events_from_annot)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    for i in range(len(raw.annotations)):\n",
    "      print(events_from_annot[i], raw.annotations[i])  \n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  class_info = \"Idling EEG (eyes open): \" + str(len(events_from_annot[events_from_annot[:, 2]==276][:, 0])) + \"\\n\" + \\\n",
    "               \"Idling EEG (eyes closed): \" + str(len(events_from_annot[events_from_annot[:, 2]==277][:, 0])) + \"\\n\" + \\\n",
    "               \"Start of a trial: \" + str(len(events_from_annot[events_from_annot[:, 2]==768][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset left (class 1): \" + str(len(events_from_annot[events_from_annot[:, 2]==769][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset right (class 2): \" + str(len(events_from_annot[events_from_annot[:, 2]==770][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset foot (class 3): \" + str(len(events_from_annot[events_from_annot[:, 2]==771][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue onset tongue (class 4): \" + str(len(events_from_annot[events_from_annot[:, 2]==772][:, 0])) + \"\\n\" + \\\n",
    "               \"Cue unknown: \" + str(len(events_from_annot[events_from_annot[:, 2]==783][:, 0])) + \"\\n\" + \\\n",
    "               \"Rejected trial: \" + str(len(events_from_annot[events_from_annot[:, 2]==1023][:, 0])) + \"\\n\" + \\\n",
    "               \"Eye movements: \" + str(len(events_from_annot[events_from_annot[:, 2]==1072][:, 0])) + \"\\n\" + \\\n",
    "               \"Start of a new run: \" + str(len(events_from_annot[events_from_annot[:, 2]==32766][:, 0]))\n",
    "  subject_data[\"class_info\"] = class_info\n",
    "\n",
    "  if debug == \"all\" or debug == \"important\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print(class_info)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  epoch_data = {\"left\": [], \"right\": [], \"foot\": [], \"tongue\": [], \"unknown\": []}\n",
    "  rejected_trial = events_from_annot[events_from_annot[:, 2]==1023][:, 0]\n",
    "  class_dict = {\"left\": 769, \"right\": 770, \"foot\": 771, \"tongue\": 772, \"unknown\": 783}\n",
    "  raw_data = raw.get_data() #(22, 672528)\n",
    "  start = 0                 # cue\n",
    "  stop = 500                # cue+3.0s\n",
    "\n",
    "  for event_class, event_id in class_dict.items():\n",
    "    current_event = events_from_annot[events_from_annot[:, 2]==event_id][:, 0]\n",
    "    if event_class == \"unknown\":\n",
    "      subject_true_labels = true_labels[name[:4]+\".mat\"]\n",
    "      class_dict_labels = {1: \"left\", 2: \"right\", 3: \"foot\", 4: \"tongue\"}\n",
    "      for i in range(len(current_event)):\n",
    "        # exclude artifact\n",
    "        if (current_event[i] - 500 != rejected_trial).all():\n",
    "          current_event_data = np.expand_dims(np.array(raw_data[:22, current_event[i]+start:current_event[i]+stop]), axis=0)\n",
    "          if (epoch_data.get(class_dict_labels[subject_true_labels[i]]) == None).all():\n",
    "            epoch_data[class_dict_labels[subject_true_labels[i]]] = current_event_data\n",
    "          else:\n",
    "            epoch_data[class_dict_labels[subject_true_labels[i]]] = np.append(epoch_data[class_dict_labels[subject_true_labels[i]]], current_event_data, axis=0)\n",
    "    else:\n",
    "      for i in range(len(current_event)):\n",
    "        # exclude artifact\n",
    "        if((current_event[i] - 500 != rejected_trial).all()):\n",
    "          epoch_data[event_class].append(np.array(raw_data[:22, current_event[i]+start:current_event[i]+stop]))\n",
    "      epoch_data[event_class] = np.array(epoch_data[event_class])\n",
    "\n",
    "  if debug == \"all\" or debug == \"important\":\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    for key, data in epoch_data.items():\n",
    "      print(key, len(data))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  for event_class, event_data in epoch_data.items():\n",
    "    epoch_data[event_class] = np.array(event_data)\n",
    "\n",
    "  subject_data[\"epoch_data\"] = epoch_data\n",
    "    \n",
    "\n",
    "  return subject_data\n",
    "\n",
    "def load_all_subject(dataset_path):\n",
    "  data = {}\n",
    "  for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "      data[file] = load_subject(name=file, dir=root) \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd to google drive\n",
    "os.chdir(\"G:\")\n",
    "\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "subject = 'fsaverage'\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "\n",
    "source = mne.read_source_spaces(src)\n",
    "left = source[0]\n",
    "right = source[1]\n",
    "left_pos = left[\"rr\"][left[\"inuse\"]==1]\n",
    "right_pos = right[\"rr\"][right[\"inuse\"]==1]\n",
    "                        \n",
    "transformation = mne.read_trans(op.join(fs_dir, \"bem\", \"fsaverage-trans.fif\"))\n",
    "\n",
    "save_path = op.join(os.getcwd(), \"Shared drives\", \"Motor Imagery\", \"Source Estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_path = \"Shared drives/Motor Imagery/BCI competition IV dataset/2a/2a true_labels/\"\n",
    "true_labels = load_all_true_labels(true_labels_path)\n",
    "\n",
    "dataset_path = 'Shared drives/Motor Imagery/BCI competition IV dataset/2a/BCICIV_2a_gdf/'\n",
    "data = load_all_subject(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c296e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some information to help to understand functions and data structure\n",
    "\"\"\"\n",
    "for key, item in data.items():\n",
    "  print(key)\n",
    "\n",
    "ch_names = data[\"A01T.gdf\"][\"info\"][\"ch_names\"]\n",
    "print(ch_names)\n",
    "\n",
    "print(data[\"A01T.gdf\"][\"class_info\"])\n",
    "\n",
    "for key, value in data.items():\n",
    "  print(key)\n",
    "  for event_class, event_data in value[\"epoch_data\"].items():\n",
    "      print(event_class, len(event_data))\n",
    "  print()\n",
    "\n",
    "subject_name = \"A01T.gdf\"\n",
    "Class = \"left\"\n",
    "filter_channels = [\"C3\", \"Cz\", \"C4\"]\n",
    "plot_average_graph(subject_name, Class, filter_channels)\n",
    "\n",
    "subject_name = \"A02T.gdf\"\n",
    "classes = [\"left\", \"right\"]\n",
    "filter_channels = [\"C3\", \"Cz\", \"C4\"]\n",
    "plot_multiple_graph(subject_name, classes, filter_channels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs(data):\n",
    "  subjects_data = {}\n",
    "\n",
    "  for subject in data.keys():\n",
    "    epochs_data = {}\n",
    "    for event in data[subject][\"epoch_data\"].keys():\n",
    "      if data[subject][\"epoch_data\"][event].any():\n",
    "        epochs_data[event] = mne.EpochsArray(data[subject][\"epoch_data\"][event], data[subject][\"info\"])\n",
    "    subjects_data[subject] = epochs_data\n",
    "\n",
    "  return subjects_data\n",
    "\n",
    "epochs = create_epochs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_epochs = epochs[\"A01T.gdf\"][\"right\"]\n",
    "my_evoked = my_epochs.average().pick(\"eeg\")\n",
    "\n",
    "noise_cov = mne.compute_covariance(my_epochs, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=False)\n",
    "fwd = mne.make_forward_solution(my_epochs.info, trans=trans, src=src,\n",
    "                            bem=bem, eeg=True, meg=False, mindist=5.0, n_jobs=1)\n",
    "# forward matrix\n",
    "fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                         use_cps=True)\n",
    "\n",
    "inverse_operator = make_inverse_operator(\n",
    "    my_epochs.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
    "\n",
    "method = \"sLORETA\"\n",
    "snr = 3.\n",
    "lambda2 = 1. / snr ** 2\n",
    "stc = mne.minimum_norm.apply_inverse(my_evoked, inverse_operator, lambda2,\n",
    "                              method=method, pick_ori=\"normal\", verbose=True)\n",
    "\n",
    "reconstruct_evoked = mne.apply_forward(fwd_fixed, stc, my_evoked.info)\n",
    "my_evoked.plot_topomap()\n",
    "reconstruct_evoked.plot_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6963ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
