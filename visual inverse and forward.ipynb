{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf541316",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs, apply_inverse\n",
    "from mne.datasets import fetch_fsaverage\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial import Delaunay\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Dense, Flatten, Concatenate, BatchNormalization, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "DIRECTORY_PATH = os.getcwd()\n",
    "EXTERNAL_STORAGE_PATH = \"D:\\Motor Imagery\"\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63ec05",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(\"/Users/ivanl/Downloads/MRIcron_windows/MRIcron/Resources/templates/brodmann.nii.gz\")\n",
    "\n",
    "brodmann_data = img.get_fdata()\n",
    "# Area 17 â€“ Primary visual cortex (V1)\n",
    "brodmann_visual = None\n",
    "selected_area = [17]\n",
    "for area in selected_area:\n",
    "    if brodmann_visual is None:\n",
    "        brodmann_visual = brodmann_data.reshape(-1) == area\n",
    "    else:\n",
    "        brodmann_visual += brodmann_data.reshape(-1) == area\n",
    "\n",
    "print(brodmann_visual)\n",
    "print(\"brodmann template shape: \" + str(brodmann_data.shape))\n",
    "print(\"chosen points: \" + str(np.sum(brodmann_visual)))\n",
    "\n",
    "shape, affine = img.shape[:3], img.affine\n",
    "coords = np.array(np.meshgrid(*(range(i) for i in shape), indexing='ij'))\n",
    "coords = np.rollaxis(coords, 0, len(shape) + 1)\n",
    "mm_coords = nib.affines.apply_affine(affine, coords)\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "my_left_points = None\n",
    "my_right_points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150aa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd to google drive\n",
    "os.chdir(\"G:\")\n",
    "\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "mne_subject = 'fsaverage'\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "\n",
    "source = mne.read_source_spaces(src)\n",
    "left = source[0]\n",
    "right = source[1]\n",
    "left_pos = left[\"rr\"][left[\"inuse\"]==1]\n",
    "right_pos = right[\"rr\"][right[\"inuse\"]==1]\n",
    "                        \n",
    "transformation = mne.read_trans(op.join(fs_dir, \"bem\", \"fsaverage-trans.fif\"))\n",
    "\n",
    "save_path = op.join(os.getcwd(), \"Shared drives\", \"Motor Imagery\", \"Source Estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b06ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create mne epochs data structure from numpy array\n",
    "merge training and evaluation data\n",
    "\"\"\"\n",
    "def create_epochs(data_path):\n",
    "    subjects_data = {}\n",
    "    files = os.listdir(data_path)\n",
    "    for file in files:\n",
    "        # load data\n",
    "        data = loadmat(op.join(data_path, file))\n",
    "        sampling_freq = data['Fs']\n",
    "        labels = data['categoryLabels'].reshape(-1)     # trials\n",
    "        epochs = data['X_3D']                           # no of channels, time, trials\n",
    "        epochs = np.moveaxis(epochs, [0, 1], [1, 2])    # trials, no of channels, time\n",
    "\n",
    "        # create info\n",
    "        GSN_128 = mne.channels.make_standard_montage('GSN-HydroCel-128')\n",
    "        ch_names = GSN_128.ch_names[:124]\n",
    "        ch_types = ['eeg'] * 124\n",
    "        info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "        info.set_montage(GSN_128)\n",
    "\n",
    "        epochs = mne.EpochsArray(epochs, info, verbose=False)\n",
    "        subjects_data[file[:-4]] = {}\n",
    "        subjects_data[file[:-4]][\"epochs\"] = epochs\n",
    "        subjects_data[file[:-4]][\"labels\"] = labels\n",
    "\n",
    "    return subjects_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create source activity and reconstructed eeg respectively for each subject\n",
    "\n",
    "For each subject, there are six events in total, i.e. \n",
    "(1=Human Body; 2=Human Face; 3=Animal Body; 4=Animal Face; 5=Fruit Vegetable; 6=Inanimate Object) \n",
    "Split these data into train and test set using kfold\n",
    "Compute the noise covariance matrix on train set and apply it to test set\n",
    "Create source activity (only motor region) first by applying an inverse operator to the epochs \n",
    "Create reconstructed eeg by applying a forward operator to the source activity acquired earlier\n",
    "Save both these files to disk\n",
    "\"\"\"\n",
    "def apply_inverse_and_forward_kfold(epochs, n_splits=5, save_inverse=True, save_forward=True):\n",
    "    global my_left_points, my_right_points\n",
    "    \n",
    "    for subject in epochs.keys():  \n",
    "        X, Y = [], []\n",
    "        info = None\n",
    "        counter = 0\n",
    "        \n",
    "        X = epochs[subject][\"epochs\"].get_data()\n",
    "        print(X.shape)\n",
    "        Y = epochs[subject][\"labels\"]\n",
    "        print(Y.shape)\n",
    "        info = epochs[subject][\"epochs\"].info\n",
    "        \n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "            counter += 1\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "            X_train = mne.EpochsArray(X_train, info, verbose=False)\n",
    "            X_test = mne.EpochsArray(X_test, info, verbose=False)\n",
    "            \n",
    "            noise_cov = mne.compute_covariance(X_train, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=False)\n",
    "            fwd = mne.make_forward_solution(info, trans=trans, src=src,\n",
    "                            bem=bem, eeg=True, meg=False, mindist=5.0, n_jobs=1, verbose=False)\n",
    "            fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                         use_cps=True, verbose=False)\n",
    "            leadfield = fwd_fixed['sol']['data']\n",
    "            inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "            \n",
    "            method = \"sLORETA\"\n",
    "            snr = 3.\n",
    "            lambda2 = 1. / snr ** 2\n",
    "            stc_train = apply_inverse_epochs(X_train, inverse_operator, lambda2,\n",
    "                                          method=method, pick_ori=\"normal\", verbose=True)\n",
    "            \n",
    "            # get motor region points (once)\n",
    "            if my_left_points is None and my_right_points is None:\n",
    "                my_source = stc_train[0]\n",
    "                mni_lh = mne.vertex_to_mni(my_source.vertices[0], 0, mne_subject)\n",
    "                #print(mni_lh.shape)\n",
    "                mni_rh = mne.vertex_to_mni(my_source.vertices[1], 1, mne_subject)\n",
    "                #print(mni_rh.shape)\n",
    "\n",
    "                \"\"\"\n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "                ax = fig.add_subplot(projection='3d')\n",
    "                ax.scatter(mm_coords.reshape(-1, 3)[brodmann_visual][:, 0], mm_coords.reshape(-1, 3)[brodmann_visual][:, 1], mm_coords.reshape(-1, 3)[brodmann_visual][:, 2], s=15, marker='|')\n",
    "                ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='_')\n",
    "                ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "                ax.set_xlabel('X Label')\n",
    "                ax.set_ylabel('Y Label')\n",
    "                ax.set_zlabel('Z Label')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "\n",
    "                my_left_points = in_hull(mni_lh, mm_coords.reshape(-1, 3)[brodmann_visual])\n",
    "                my_right_points = in_hull(mni_rh, mm_coords.reshape(-1, 3)[brodmann_visual])\n",
    "\n",
    "                mni_left_motor = mne.vertex_to_mni(my_source.vertices[0][my_left_points], 0, mne_subject)\n",
    "                #print(mni_left_motor.shape)\n",
    "                mni_right_motor = mne.vertex_to_mni(my_source.vertices[1][my_right_points], 1, mne_subject)\n",
    "                #print(mni_right_motor.shape)\n",
    "\n",
    "                \"\"\"\n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "                ax = fig.add_subplot(projection='3d')\n",
    "                ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='|')\n",
    "                ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "                ax.scatter(mni_left_motor[:, 0], mni_left_motor[:, 1], mni_left_motor[:, 2], s=15, marker='o')\n",
    "                ax.scatter(mni_right_motor[:, 0], mni_right_motor[:, 1], mni_right_motor[:, 2], s=15, marker='^')\n",
    "                ax.set_xlabel('X Label')\n",
    "                ax.set_ylabel('Y Label')\n",
    "                ax.set_zlabel('Z Label')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                \n",
    "            #print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)\n",
    "            #print(stc_train[0].data.shape)\n",
    "            \n",
    "            # train set\n",
    "            # slice source activity data\n",
    "            left_hemi_data = []\n",
    "            right_hemi_data = []\n",
    "            for source in stc_train:\n",
    "                left_hemi_data.append(source.data[:len(source.vertices[0])][my_left_points])\n",
    "                right_hemi_data.append(source.data[-len(source.vertices[1]):][my_right_points])\n",
    "            left_hemi_data = np.array(left_hemi_data)\n",
    "            right_hemi_data = np.array(right_hemi_data)\n",
    "            if save_inverse:\n",
    "                source_activity_path = op.join(EXTERNAL_STORAGE_PATH, \"data\", \"source activity\", subject)\n",
    "                if not op.exists(source_activity_path):\n",
    "                    os.makedirs(source_activity_path)\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_train_X.npz\"), data=np.append(left_hemi_data, right_hemi_data, axis=1))\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_train_Y.npz\"), data=Y_train)\n",
    "            # slice reconstructed eeg data\n",
    "            reconstructed_eeg_data = []\n",
    "            for source in stc_train:\n",
    "                motor_source = np.zeros_like(source.data)\n",
    "                motor_source[:len(source.vertices[0])][my_left_points] = source.data[:len(source.vertices[0])][my_left_points]\n",
    "                motor_source[-len(source.vertices[1]):][my_right_points] = source.data[-len(source.vertices[1]):][my_right_points]\n",
    "                motor_eeg = np.dot(leadfield, motor_source)\n",
    "                reconstructed_eeg_data.append(motor_eeg)\n",
    "            if save_forward:\n",
    "                reconstructed_eeg_path = op.join(EXTERNAL_STORAGE_PATH, \"data\", \"reconstructed eeg\", subject)\n",
    "                if not op.exists(reconstructed_eeg_path):\n",
    "                    os.makedirs(reconstructed_eeg_path)\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_train_X.npz\"), data=np.array(reconstructed_eeg_data))\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_train_Y.npz\"), data=Y_train)\n",
    "            \n",
    "            del stc_train\n",
    "            gc.collect()\n",
    "            \n",
    "            stc_test = apply_inverse_epochs(X_test, inverse_operator, lambda2,\n",
    "                              method=method, pick_ori=\"normal\", verbose=True)\n",
    "            # test set\n",
    "            # slice source activity data\n",
    "            left_hemi_data = []\n",
    "            right_hemi_data = []\n",
    "            for source in stc_test:\n",
    "                left_hemi_data.append(source.data[:len(source.vertices[0])][my_left_points])\n",
    "                right_hemi_data.append(source.data[-len(source.vertices[1]):][my_right_points])\n",
    "            left_hemi_data = np.array(left_hemi_data)\n",
    "            right_hemi_data = np.array(right_hemi_data)\n",
    "            if save_inverse:\n",
    "                source_activity_path = op.join(EXTERNAL_STORAGE_PATH, \"data\", \"source activity\", subject)\n",
    "                if not op.exists(source_activity_path):\n",
    "                    os.makedirs(source_activity_path)\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_test_X.npz\"), data=np.append(left_hemi_data, right_hemi_data, axis=1))\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_test_Y.npz\"), data=Y_test)\n",
    "            # slice reconstructed eeg data\n",
    "            reconstructed_eeg_data = []\n",
    "            for source in stc_test:\n",
    "                motor_source = np.zeros_like(source.data)\n",
    "                motor_source[:len(source.vertices[0])][my_left_points] = source.data[:len(source.vertices[0])][my_left_points]\n",
    "                motor_source[-len(source.vertices[1]):][my_right_points] = source.data[-len(source.vertices[1]):][my_right_points]\n",
    "                motor_eeg = np.dot(leadfield, motor_source)\n",
    "                reconstructed_eeg_data.append(motor_eeg)\n",
    "            if save_forward:\n",
    "                reconstructed_eeg_path = op.join(EXTERNAL_STORAGE_PATH, \"data\", \"reconstructed eeg\", subject)\n",
    "                if not op.exists(reconstructed_eeg_path):\n",
    "                    os.makedirs(reconstructed_eeg_path)\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_test_X.npz\"), data=np.array(reconstructed_eeg_data))\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_test_Y.npz\"), data=Y_test)\n",
    "            \n",
    "            del X_train, X_test, Y_train, Y_test\n",
    "            del stc_test, reconstructed_eeg_data, left_hemi_data, right_hemi_data\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Shared drives/Motor Imagery/Visual Dataset\"\n",
    "    \n",
    "epochs = create_epochs(data_path)\n",
    "print(epochs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41580ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "\n",
    "apply_inverse_and_forward_kfold(epochs, n_splits=n_splits, save_inverse=True, save_forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
