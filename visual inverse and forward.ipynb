{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf541316",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse_epochs, apply_inverse\n",
    "from mne.datasets import fetch_fsaverage\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy import stats\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D, MaxPool2D, AveragePooling2D, GlobalAveragePooling2D, Dense, Activation, Flatten, Concatenate, BatchNormalization, Dropout, Input, Conv1D, ReLU, MaxPooling1D\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import json\n",
    "import multiprocessing\n",
    "from scipy.spatial import KDTree\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "from nilearn import plotting\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "DIRECTORY_PATH = os.getcwd()\n",
    "EXTERNAL_STORAGE_PATH = \"E:\\Motor Imagery\"\n",
    "RECONSTRUCT_SAVE_FOLDER = \"v3-v5 region\"\n",
    "n_splits = 5\n",
    "\n",
    "# force tensorflow to use cpu when facing memory issue\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63ec05",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(\"/Users/ivanlim/Downloads/MRIcron_windows/MRIcron/Resources/templates/brodmann.nii.gz\")\n",
    "ch2_img = nib.load(\"C:/Users/ivanlim/Downloads/MRIcron_windows/MRIcron/Resources/templates/ch2.nii.gz\")\n",
    "\n",
    "brodmann_data = img.get_fdata()\n",
    "\"\"\"\n",
    "motor\n",
    "\"\"\"\n",
    "# Area 4– Primary motor cortex\n",
    "\"\"\"\n",
    "visual\n",
    "\"\"\"\n",
    "# Area 17 – Primary visual cortex (V1)\n",
    "# Area 18 – Secondary visual cortex (V2)\n",
    "# Area 19 – Associative visual cortex (V3, V4, V5)\n",
    "# Area 20 – Inferior temporal gyrus\n",
    "# Area 21 – Middle temporal gyrus\n",
    "# Area 22 – Part of the superior temporal gyrus, included in Wernicke's area\n",
    "# Area 37 – Fusiform gyrus\n",
    "brodmann_visual = []\n",
    "selected_area = [17, 18, 19, 20, 21, 22, 37]\n",
    "#selected_area = [17, 18, 19]\n",
    "\n",
    "# old: compute one convex hull for all the selected regions\n",
    "# new: compute a single convex hull for one selected region then combine them together\n",
    "reconstruct_mode = \"new\"\n",
    "\n",
    "for area in selected_area:\n",
    "    if reconstruct_mode == \"old\":\n",
    "        if len(brodmann_visual) == 0:\n",
    "            brodmann_visual.append(brodmann_data.reshape(-1) == area)\n",
    "        else:\n",
    "            brodmann_visual[0] += brodmann_data.reshape(-1) == area\n",
    "    else:\n",
    "        brodmann_visual.append(brodmann_data.reshape(-1) == area)\n",
    "\n",
    "print(brodmann_visual)\n",
    "print(\"brodmann template shape: \" + str(brodmann_data.shape))\n",
    "if reconstruct_mode == \"old\":\n",
    "    print(\"chosen points: \" + str(np.sum(brodmann_visual[0])))\n",
    "else:\n",
    "    chosen_points = None\n",
    "    for selected_region in brodmann_visual:\n",
    "        print(np.sum(selected_region))\n",
    "        if chosen_points is None:\n",
    "            chosen_points = np.array(selected_region, copy=True)\n",
    "        else:\n",
    "            chosen_points += selected_region\n",
    "    print(\"chosen points: \" + str(np.sum(chosen_points)))\n",
    "        \n",
    "shape, affine = img.shape[:3], img.affine\n",
    "coords = np.array(np.meshgrid(*(range(i) for i in shape), indexing='ij'))\n",
    "coords = np.rollaxis(coords, 0, len(shape) + 1)\n",
    "mm_coords = nib.affines.apply_affine(affine, coords)\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "my_left_points = None\n",
    "my_right_points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150aa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd to google drive\n",
    "os.chdir(\"G:\")\n",
    "\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "mne_subject = 'fsaverage'\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif')\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "\n",
    "source = mne.read_source_spaces(src)\n",
    "left = source[0]\n",
    "right = source[1]\n",
    "left_pos = left[\"rr\"][left[\"inuse\"]==1]\n",
    "right_pos = right[\"rr\"][right[\"inuse\"]==1]\n",
    "                        \n",
    "transformation = mne.read_trans(op.join(fs_dir, \"bem\", \"fsaverage-trans.fif\"))\n",
    "\n",
    "save_path = op.join(os.getcwd(), \"Shared drives\", \"Motor Imagery\", \"Source Estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b06ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create mne epochs data structure from numpy array\n",
    "merge training and evaluation data\n",
    "\"\"\"\n",
    "def create_epochs(data_path):\n",
    "    subjects_data = {}\n",
    "    files = os.listdir(data_path)\n",
    "    for file in files:\n",
    "        # load data\n",
    "        data = loadmat(op.join(data_path, file))\n",
    "        sampling_freq = data['Fs']\n",
    "        labels = data['categoryLabels'].reshape(-1)     # trials\n",
    "        epochs = data['X_3D']                           # no of channels, time, trials\n",
    "        epochs = np.moveaxis(epochs, [0, 1], [1, 2])    # trials, no of channels, time\n",
    "\n",
    "        # create info\n",
    "        GSN_128 = mne.channels.make_standard_montage('GSN-HydroCel-128')\n",
    "        ch_names = GSN_128.ch_names[:124]\n",
    "        ch_types = ['eeg'] * 124\n",
    "        info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "        info.set_montage(GSN_128)\n",
    "\n",
    "        # create epochs\n",
    "        epochs = mne.EpochsArray(epochs, info, verbose=False)\n",
    "        \n",
    "        # Set common average reference\n",
    "        epochs.set_eeg_reference('average', projection=True, verbose=False)\n",
    "        \n",
    "        subjects_data[file[:-4]] = {}\n",
    "        subjects_data[file[:-4]][\"epochs\"] = epochs\n",
    "        subjects_data[file[:-4]][\"labels\"] = labels\n",
    "\n",
    "    return subjects_data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def create_model(model_name=\"default\"):\n",
    "    if model_name == \"default\":\n",
    "        model = tf.keras.models.Sequential([\n",
    "            Conv1D(filters=200, kernel_size=3, strides=1, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            ReLU(),\n",
    "            Flatten(),\n",
    "            Dense(6, activation=\"softmax\")\n",
    "        ])\n",
    "    elif model_name == \"eegnet\":\n",
    "        model = tf.keras.models.Sequential([\n",
    "                Conv2D(16, (1, 8), use_bias = False, activation = 'linear', padding='same', name = 'Spectral_filter'),\n",
    "                BatchNormalization(),\n",
    "                DepthwiseConv2D((124, 1), use_bias = False, padding='valid', depth_multiplier = 2, activation = 'linear',\n",
    "                depthwise_constraint = tf.keras.constraints.MaxNorm(max_value=1), name = 'Spatial_filter'),\n",
    "                BatchNormalization(),\n",
    "                Activation('elu'),\n",
    "                AveragePooling2D((1, 2)),\n",
    "                Dropout(0.5),\n",
    "                SeparableConv2D(32, (1, 4), use_bias = False, activation = 'linear', padding = 'same'),\n",
    "                BatchNormalization(),\n",
    "                Activation('elu'),\n",
    "                AveragePooling2D((1, 2)),\n",
    "                Dropout(0.5),\n",
    "                Flatten(),\n",
    "                Dense(6, activation = 'softmax', kernel_constraint = max_norm(0.25))\n",
    "            ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create source activity and reconstructed eeg respectively for each subject\n",
    "\n",
    "For each subject, there are six events in total, i.e. \n",
    "(1=Human Body; 2=Human Face; 3=Animal Body; 4=Animal Face; 5=Fruit Vegetable; 6=Inanimate Object) \n",
    "Split these data into train and test set using kfold\n",
    "Compute the noise covariance matrix on train set and apply it to test set\n",
    "Create source activity (only visual region) first by applying an inverse operator to the epochs \n",
    "Create reconstructed eeg by applying a forward operator to the source activity acquired earlier\n",
    "Save both these files to disk\n",
    "\"\"\"\n",
    "def apply_inverse_and_forward_kfold(epochs, n_splits=5, save_inverse=True, save_forward=True, subjects=None):\n",
    "    global my_left_points, my_right_points\n",
    "    \n",
    "    if subjects is None:\n",
    "        subjects = epochs.keys()\n",
    "    \n",
    "    for subject in subjects:  \n",
    "        X, Y = [], []\n",
    "        info = None\n",
    "        counter = 0\n",
    "        \n",
    "        X = epochs[subject][\"epochs\"].get_data()\n",
    "        print(X.shape)\n",
    "        Y = epochs[subject][\"labels\"]\n",
    "        print(Y.shape)\n",
    "        info = epochs[subject][\"epochs\"].info\n",
    "        \n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "            counter += 1\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "            X_train = mne.EpochsArray(X_train, info, verbose=False)\n",
    "            X_test = mne.EpochsArray(X_test, info, verbose=False)\n",
    "            \n",
    "            noise_cov = mne.compute_covariance(X_train, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=False)\n",
    "            fwd = mne.make_forward_solution(info, trans=trans, src=src,\n",
    "                            bem=bem, eeg=True, meg=False, mindist=5.0, n_jobs=1, verbose=False)\n",
    "            fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                         use_cps=True, verbose=False)\n",
    "            leadfield = fwd_fixed['sol']['data']\n",
    "            inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "            \n",
    "            method = \"sLORETA\"\n",
    "            snr = 3.\n",
    "            lambda2 = 1. / snr ** 2\n",
    "            stc_train = apply_inverse_epochs(X_train, inverse_operator, lambda2,\n",
    "                                          method=method, pick_ori=\"normal\", verbose=True)\n",
    "            \n",
    "            # get visual region points (once)\n",
    "            if my_left_points is None and my_right_points is None:\n",
    "                my_source = stc_train[0]\n",
    "                mni_lh = mne.vertex_to_mni(my_source.vertices[0], 0, mne_subject)\n",
    "                #print(mni_lh.shape)\n",
    "                mni_rh = mne.vertex_to_mni(my_source.vertices[1], 1, mne_subject)\n",
    "                #print(mni_rh.shape)\n",
    "\n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "                ax = fig.add_subplot(projection='3d')\n",
    "                for selected_region in brodmann_visual:\n",
    "                    ax.scatter(mm_coords.reshape(-1, 3)[selected_region][:, 0], mm_coords.reshape(-1, 3)[selected_region][:, 1], mm_coords.reshape(-1, 3)[selected_region][:, 2], s=15, marker='|')\n",
    "                ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='_')\n",
    "                ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "                ax.set_xlabel('X')\n",
    "                ax.set_ylabel('Y')\n",
    "                ax.set_zlabel('Z')\n",
    "                plt.show()\n",
    "\n",
    "                my_left_points = None\n",
    "                my_right_points = None\n",
    "                for selected_region in brodmann_visual:\n",
    "                    print(np.sum(selected_region))\n",
    "                    if my_left_points is None:\n",
    "                        my_left_points = in_hull(mni_lh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "                        my_right_points = in_hull(mni_rh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "                    else:\n",
    "                        my_left_points += in_hull(mni_lh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "                        my_right_points += in_hull(mni_rh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "\n",
    "                mni_left_visual = mne.vertex_to_mni(my_source.vertices[0][my_left_points], 0, mne_subject)\n",
    "                print(mni_left_visual.shape)\n",
    "                mni_right_visual = mne.vertex_to_mni(my_source.vertices[1][my_right_points], 1, mne_subject)\n",
    "                print(mni_right_visual.shape)\n",
    "\n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "                ax = fig.add_subplot(projection='3d')\n",
    "                ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='|')\n",
    "                ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "                ax.scatter(mni_left_visual[:, 0], mni_left_visual[:, 1], mni_left_visual[:, 2], s=15, marker='o')\n",
    "                ax.scatter(mni_right_visual[:, 0], mni_right_visual[:, 1], mni_right_visual[:, 2], s=15, marker='^')\n",
    "                ax.set_xlabel('X')\n",
    "                ax.set_ylabel('Y')\n",
    "                ax.set_zlabel('Z')\n",
    "                plt.show()\n",
    "                \n",
    "            print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)\n",
    "            #print(stc_train[0].data.shape)\n",
    "            \n",
    "            # train set\n",
    "            # slice source activity data\n",
    "            left_hemi_data = []\n",
    "            right_hemi_data = []\n",
    "            for source in stc_train:\n",
    "                left_hemi_data.append(source.data[:len(source.vertices[0])][my_left_points])\n",
    "                right_hemi_data.append(source.data[-len(source.vertices[1]):][my_right_points])\n",
    "            left_hemi_data = np.array(left_hemi_data)\n",
    "            right_hemi_data = np.array(right_hemi_data)\n",
    "            if save_inverse:\n",
    "                source_activity_path = op.join(EXTERNAL_STORAGE_PATH, RECONSTRUCT_SAVE_FOLDER, \"data\", \"source activity\", subject)\n",
    "                if not op.exists(source_activity_path):\n",
    "                    os.makedirs(source_activity_path)\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_train_X.npz\"), data=np.append(left_hemi_data, right_hemi_data, axis=1))\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_train_Y.npz\"), data=Y_train)\n",
    "            # slice reconstructed eeg data\n",
    "            reconstructed_eeg_data = []\n",
    "            for source in stc_train:\n",
    "                visual_source = np.zeros_like(source.data)\n",
    "                visual_source[:len(source.vertices[0])][my_left_points] = source.data[:len(source.vertices[0])][my_left_points]\n",
    "                visual_source[-len(source.vertices[1]):][my_right_points] = source.data[-len(source.vertices[1]):][my_right_points]\n",
    "                visual_eeg = np.dot(leadfield, visual_source)\n",
    "                reconstructed_eeg_data.append(visual_eeg)\n",
    "            if save_forward:\n",
    "                reconstructed_eeg_path = op.join(EXTERNAL_STORAGE_PATH, RECONSTRUCT_SAVE_FOLDER, \"data\", \"reconstructed eeg\", subject)\n",
    "                if not op.exists(reconstructed_eeg_path):\n",
    "                    os.makedirs(reconstructed_eeg_path)\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_train_X.npz\"), data=np.array(reconstructed_eeg_data))\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_train_Y.npz\"), data=Y_train)\n",
    "            \n",
    "            del stc_train\n",
    "            gc.collect()\n",
    "            \n",
    "            stc_test = apply_inverse_epochs(X_test, inverse_operator, lambda2,\n",
    "                              method=method, pick_ori=\"normal\", verbose=True)\n",
    "            # test set\n",
    "            # slice source activity data\n",
    "            left_hemi_data = []\n",
    "            right_hemi_data = []\n",
    "            for source in stc_test:\n",
    "                left_hemi_data.append(source.data[:len(source.vertices[0])][my_left_points])\n",
    "                right_hemi_data.append(source.data[-len(source.vertices[1]):][my_right_points])\n",
    "            left_hemi_data = np.array(left_hemi_data)\n",
    "            right_hemi_data = np.array(right_hemi_data)\n",
    "            if save_inverse:\n",
    "                source_activity_path = op.join(EXTERNAL_STORAGE_PATH, RECONSTRUCT_SAVE_FOLDER, \"data\", \"source activity\", subject)\n",
    "                if not op.exists(source_activity_path):\n",
    "                    os.makedirs(source_activity_path)\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_test_X.npz\"), data=np.append(left_hemi_data, right_hemi_data, axis=1))\n",
    "                np.savez_compressed(op.join(source_activity_path, str(counter)+\"_test_Y.npz\"), data=Y_test)\n",
    "            # slice reconstructed eeg data\n",
    "            reconstructed_eeg_data = []\n",
    "            for source in stc_test:\n",
    "                visual_source = np.zeros_like(source.data)\n",
    "                visual_source[:len(source.vertices[0])][my_left_points] = source.data[:len(source.vertices[0])][my_left_points]\n",
    "                visual_source[-len(source.vertices[1]):][my_right_points] = source.data[-len(source.vertices[1]):][my_right_points]\n",
    "                visual_eeg = np.dot(leadfield, visual_source)\n",
    "                reconstructed_eeg_data.append(visual_eeg)\n",
    "            if save_forward:\n",
    "                reconstructed_eeg_path = op.join(EXTERNAL_STORAGE_PATH, RECONSTRUCT_SAVE_FOLDER, \"data\", \"reconstructed eeg\", subject)\n",
    "                if not op.exists(reconstructed_eeg_path):\n",
    "                    os.makedirs(reconstructed_eeg_path)\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_test_X.npz\"), data=np.array(reconstructed_eeg_data))\n",
    "                np.savez_compressed(op.join(reconstructed_eeg_path, str(counter)+\"_test_Y.npz\"), data=Y_test)\n",
    "            \n",
    "            del X_train, X_test, Y_train, Y_test\n",
    "            del stc_test, reconstructed_eeg_data, left_hemi_data, right_hemi_data\n",
    "            gc.collect()\n",
    "               \n",
    "def get_inverse_and_forward_information(epochs):\n",
    "    \n",
    "    subject = \"S1\"\n",
    "    X, Y = [], []\n",
    "    info = None\n",
    "    \n",
    "    X = epochs[subject][\"epochs\"].get_data()\n",
    "    print(X.shape)\n",
    "    Y = epochs[subject][\"labels\"]\n",
    "    print(Y.shape)\n",
    "    info = epochs[subject][\"epochs\"].info\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    X_epochs = mne.EpochsArray(X, info, verbose=False)\n",
    "    X_evoked = X_epochs.average().pick(\"eeg\")\n",
    "\n",
    "    noise_cov = mne.compute_covariance(X_epochs, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=False)\n",
    "    fwd = mne.make_forward_solution(info, trans=trans, src=src,\n",
    "                    bem=bem, eeg=True, meg=False, mindist=5.0, n_jobs=1, verbose=False)\n",
    "    fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                 use_cps=True, verbose=False)\n",
    "    leadfield = fwd_fixed['sol']['data']\n",
    "    inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "\n",
    "    method = \"sLORETA\"\n",
    "    snr = 3.\n",
    "    lambda2 = 1. / snr ** 2\n",
    "    stc = apply_inverse(X_evoked, inverse_operator, lambda2, method=method, pick_ori=\"normal\", verbose=True)\n",
    "\n",
    "    # get visual region points\n",
    "    my_source = stc\n",
    "    mni_lh = mne.vertex_to_mni(my_source.vertices[0], 0, mne_subject)\n",
    "    print(mni_lh.shape)\n",
    "    mni_rh = mne.vertex_to_mni(my_source.vertices[1], 1, mne_subject)\n",
    "    print(mni_rh.shape)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    for selected_region in brodmann_visual:\n",
    "        ax.scatter(mm_coords.reshape(-1, 3)[selected_region][:, 0], mm_coords.reshape(-1, 3)[selected_region][:, 1], mm_coords.reshape(-1, 3)[selected_region][:, 2], s=15, marker='|')\n",
    "    ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='_')\n",
    "    ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.show()\n",
    "\n",
    "    my_left_points = None\n",
    "    my_right_points = None\n",
    "    for selected_region in brodmann_visual:\n",
    "        print(np.sum(selected_region))\n",
    "        if my_left_points is None:\n",
    "            my_left_points = in_hull(mni_lh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "            my_right_points = in_hull(mni_rh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "        else:\n",
    "            my_left_points += in_hull(mni_lh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "            my_right_points += in_hull(mni_rh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "\n",
    "    mni_left_visual = mne.vertex_to_mni(my_source.vertices[0][my_left_points], 0, mne_subject)\n",
    "    print(mni_left_visual.shape)\n",
    "    mni_right_visual = mne.vertex_to_mni(my_source.vertices[1][my_right_points], 1, mne_subject)\n",
    "    print(mni_right_visual.shape)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='|')\n",
    "    ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "    ax.scatter(mni_left_visual[:, 0], mni_left_visual[:, 1], mni_left_visual[:, 2], s=15, marker='o')\n",
    "    ax.scatter(mni_right_visual[:, 0], mni_right_visual[:, 1], mni_right_visual[:, 2], s=15, marker='^')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)\n",
    "    print(stc.data.shape)\n",
    "\n",
    "    information = {\"my_left_points\": my_left_points, \n",
    "                   \"my_right_points\": my_right_points, \n",
    "                   \"stc_data_shape\": stc.data.shape, \n",
    "                   \"leadfield\": leadfield,\n",
    "                   \"left_vertices\": stc.vertices[0],\n",
    "                   \"right_vertices\": stc.vertices[1],\n",
    "                   \"inverse_operator\": inverse_operator}\n",
    "\n",
    "    return information\n",
    "\n",
    "\"\"\"\n",
    "plot original data evoked topomap and reconstruct data topomap\n",
    "original data -> source activity (only visual) -> reconstruct eeg\n",
    "\"\"\"\n",
    "def plot_evoked_topomap(epochs):\n",
    "    global my_left_points, my_right_points\n",
    "    for subject in epochs.keys():  \n",
    "        X, Y = [], []\n",
    "        info = None\n",
    "        counter = 0\n",
    "\n",
    "        X = epochs[subject][\"epochs\"]\n",
    "        print(X.get_data().shape)\n",
    "        Y = epochs[subject][\"labels\"]\n",
    "        print(Y.shape)\n",
    "        info = epochs[subject][\"epochs\"].info\n",
    "\n",
    "        noise_cov = mne.compute_covariance(X, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=False)\n",
    "        fwd = mne.make_forward_solution(info, trans=trans, src=src,\n",
    "                        bem=bem, eeg=True, meg=False, mindist=5.0, n_jobs=1, verbose=False)\n",
    "        fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                     use_cps=True, verbose=False)\n",
    "        leadfield = fwd_fixed['sol']['data']\n",
    "        inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "\n",
    "        method = \"sLORETA\"\n",
    "        snr = 3.\n",
    "        lambda2 = 1. / snr ** 2\n",
    "        stc = apply_inverse_epochs(X, inverse_operator, lambda2,\n",
    "                                      method=method, pick_ori=\"normal\", verbose=True)\n",
    "\n",
    "        # get visual region points (once)\n",
    "        if my_left_points is None and my_right_points is None:\n",
    "            my_source = stc[0]\n",
    "            mni_lh = mne.vertex_to_mni(my_source.vertices[0], 0, mne_subject)\n",
    "            print(mni_lh.shape)\n",
    "            mni_rh = mne.vertex_to_mni(my_source.vertices[1], 1, mne_subject)\n",
    "            print(mni_rh.shape)\n",
    "\n",
    "            \"\"\"\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "            for selected_region in brodmann_visual:\n",
    "                ax.scatter(mm_coords.reshape(-1, 3)[selected_region][:, 0], mm_coords.reshape(-1, 3)[selected_region][:, 1], mm_coords.reshape(-1, 3)[selected_region][:, 2], s=15, marker='|')\n",
    "            ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='_')\n",
    "            ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_zlabel('Z')\n",
    "            plt.show()\n",
    "            \"\"\"\n",
    "            \n",
    "            my_left_points = None\n",
    "            my_right_points = None\n",
    "            for selected_region in brodmann_visual:\n",
    "                if my_left_points is None:\n",
    "                    my_left_points = in_hull(mni_lh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "                    my_right_points = in_hull(mni_rh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "                else:\n",
    "                    my_left_points += in_hull(mni_lh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "                    my_right_points += in_hull(mni_rh, mm_coords.reshape(-1, 3)[selected_region])\n",
    "\n",
    "            mni_left_visual = mne.vertex_to_mni(my_source.vertices[0][my_left_points], 0, mne_subject)\n",
    "            print(mni_left_visual.shape)\n",
    "            mni_right_visual = mne.vertex_to_mni(my_source.vertices[1][my_right_points], 1, mne_subject)\n",
    "            print(mni_right_visual.shape)\n",
    "\n",
    "            \"\"\"\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "            ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='|')\n",
    "            ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "            ax.scatter(mni_left_visual[:, 0], mni_left_visual[:, 1], mni_left_visual[:, 2], s=15, marker='o')\n",
    "            ax.scatter(mni_right_visual[:, 0], mni_right_visual[:, 1], mni_right_visual[:, 2], s=15, marker='^')\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            ax.set_zlabel('Z')\n",
    "            plt.show()\n",
    "            \"\"\"\n",
    "\n",
    "        #print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)\n",
    "        #print(stc_train[0].data.shape)\n",
    "\n",
    "        # slice reconstructed eeg data\n",
    "        reconstructed_eeg_data = []\n",
    "        for source in stc:\n",
    "            visual_source = np.zeros_like(source.data)\n",
    "            visual_source[:len(source.vertices[0])][my_left_points] = source.data[:len(source.vertices[0])][my_left_points]\n",
    "            visual_source[-len(source.vertices[1]):][my_right_points] = source.data[-len(source.vertices[1]):][my_right_points]\n",
    "            visual_eeg = np.dot(leadfield, visual_source)\n",
    "            reconstructed_eeg_data.append(visual_eeg)\n",
    "\n",
    "        reconstructed_eeg_data = np.array(reconstructed_eeg_data)\n",
    "        print(reconstructed_eeg_data.shape)\n",
    "        reconstructed_eeg_data = mne.EpochsArray(reconstructed_eeg_data, info, verbose=False)\n",
    "\n",
    "        # plot evoked topomap\n",
    "        print(subject)\n",
    "        times = np.linspace(0.0, 0.496, 10)\n",
    "        evoked = X.average().pick('eeg')\n",
    "        evoked.plot_topomap(times)\n",
    "        reconstructed_evoked = reconstructed_eeg_data.average().pick('eeg')\n",
    "        reconstructed_evoked.plot_topomap(times)\n",
    "\n",
    "        del stc, reconstructed_eeg_data, X, Y\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mask(x):\n",
    "  return tf.cast(tf.greater_equal(x, 1), tf.float32)\n",
    "\n",
    "def diff_mask(mask_op):\n",
    "  @tf.custom_gradient\n",
    "  def _diff_mask(x):\n",
    "    def grad(dy):\n",
    "      return dy * tf.ones_like(x)\n",
    "    return mask_op(x), grad\n",
    "  return _diff_mask\n",
    "\n",
    "\"\"\"\n",
    "Total params: \n",
    "Trainable params: \n",
    "Non-trainable params: \n",
    "\"\"\"\n",
    "class AutoSelect(tf.keras.Model):\n",
    "    def __init__(self, forward_matrix, random_select, use_mask, model_name='default'):\n",
    "        super(AutoSelect, self).__init__()\n",
    "        # preprocessing\n",
    "        self.forward_matrix = tf.transpose(tf.constant(forward_matrix), perm=[1, 0])\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.source_select = Dense(forward_matrix.shape[1], activation=None)\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "        self.model_name = model_name\n",
    "        self.random_select = random_select\n",
    "        self.use_mask = use_mask\n",
    "        self.mask = tf.Variable(np.ones((1, forward_matrix.shape[1])), dtype=tf.float32)\n",
    "        #self.mask = tf.Variable(np.random.rand(1, forward_matrix.shape[1])+0.5, dtype=tf.float32)\n",
    "        \n",
    "        # classifier\n",
    "        self.conv1 = Conv1D(filters=200, kernel_size=3, strides=1, padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.relu1 = ReLU()\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(6, activation=\"softmax\")\n",
    "        \n",
    "        # eegnet\n",
    "        if model_name == \"eegnet\":\n",
    "            self.eegnet_model = tf.keras.models.Sequential([\n",
    "                Conv2D(16, (1, 8), use_bias = False, activation = 'linear', padding='same', name = 'Spectral_filter'),\n",
    "                BatchNormalization(),\n",
    "                DepthwiseConv2D((124, 1), use_bias = False, padding='valid', depth_multiplier = 2, activation = 'linear',\n",
    "                depthwise_constraint = tf.keras.constraints.MaxNorm(max_value=1), name = 'Spatial_filter'),\n",
    "                BatchNormalization(),\n",
    "                Activation('elu'),\n",
    "                AveragePooling2D((1, 2)),\n",
    "                Dropout(0.5),\n",
    "                SeparableConv2D(32, (1, 4), use_bias = False, activation = 'linear', padding = 'same'),\n",
    "                BatchNormalization(),\n",
    "                Activation('elu'),\n",
    "                AveragePooling2D((1, 2)),\n",
    "                Dropout(0.5),\n",
    "                Flatten(),\n",
    "                Dense(6, activation = 'softmax', kernel_constraint = max_norm(0.25))\n",
    "            ])\n",
    "\n",
    "    def call(self, inputs):                                   # (n, X, 32)\n",
    "        # preprocessing\n",
    "        x = tf.transpose(inputs, perm=[0, 2, 1])              # (n, 32, X)\n",
    "            \n",
    "        if self.random_select:\n",
    "            x = self.dropout(x)                               # (n, 32, X)\n",
    "        else:\n",
    "            if self.use_mask:\n",
    "                #tf.print(self.mask)\n",
    "                mask = diff_mask(my_mask)(self.mask)          # (1, X)\n",
    "                x = x * mask                                  # (n, 32, X)                  \n",
    "            else:\n",
    "                source_select = self.source_select(x)         # (n, 32, X)\n",
    "                source_select = self.dropout(source_select)   \n",
    "                source_select = self.sigmoid(source_select)\n",
    "                x = x * source_select                         # (n, 32, X)\n",
    "        \n",
    "        x = tf.matmul(x, self.forward_matrix)                 # (n, 32, 124)\n",
    "        #print(x)\n",
    "        \n",
    "        # classifier\n",
    "        if self.model_name == \"default\":\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.flatten(x)\n",
    "            x = self.dense1(x)\n",
    "        elif self.model_name == \"eegnet\":\n",
    "            x = tf.transpose(x, [0, 2, 1])\n",
    "            x = tf.expand_dims(x, axis=-1)                    # (n, 124, 32, 1)\n",
    "            x = self.eegnet_model(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Shared drives/Motor Imagery/Visual Dataset\"\n",
    "    \n",
    "epochs = create_epochs(data_path)\n",
    "print(epochs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41580ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#apply_inverse_and_forward_kfold(epochs, n_splits=n_splits, save_inverse=True, save_forward=True)\n",
    "#plot_evoked_topomap(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23af608",
   "metadata": {},
   "source": [
    "# Classification (Original Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94553e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labels\n",
    "1=Human Body; 2=Human Face; 3=Animal Body; 4=Animal Face; 5=Fruit Vegetable; 6=Inanimate Object\n",
    "\n",
    "channels\n",
    "124\n",
    "\"\"\"\n",
    "\n",
    "results = {\"S1\": {}, \"S2\": {}, \"S3\": {}, \"S4\": {}, \"S5\": {}, \"S6\": {}, \"S7\": {}, \"S8\": {}, \"S9\": {}, \"S10\": {}}\n",
    "debug = True\n",
    "training = True\n",
    "model_name = \"eegnet\"\n",
    "\n",
    "# train model on each subject individually\n",
    "data_list = []\n",
    "for subject in results.keys():\n",
    "  data_list.append(subject)\n",
    "\n",
    "# train model on individual subject\n",
    "# data_list = []\n",
    "# data_list.append(\"S1\")\n",
    "\n",
    "for data_name in data_list:\n",
    "  accuracy = 0\n",
    "  precision = 0\n",
    "  recall = 0\n",
    "  f1 = 0\n",
    "  kappa = 0\n",
    "  Confusion_matrix = []\n",
    "\n",
    "  X = epochs[data_name][\"epochs\"].get_data()\n",
    "  Y = epochs[data_name][\"labels\"]\n",
    "  X = np.array(X)\n",
    "  Y = np.array(Y)\n",
    "    \n",
    "  skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "  for train_index, test_index in skf.split(X, Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    Y_train -= 1\n",
    "    Y_test -= 1\n",
    "    \n",
    "    X_train = np.swapaxes(X_train, 1, 2)\n",
    "    X_test = np.swapaxes(X_test, 1, 2)\n",
    "    \n",
    "#     X_train_shape = X_train.shape\n",
    "#     X_test_shape = X_test.shape\n",
    "#     X_train = X_train.reshape(X_train_shape[0], -1)\n",
    "#     X_test = X_test.reshape(X_test_shape[0], -1)\n",
    "#     print(X_train.shape, X_test.shape)\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     X_train = X_train.reshape(X_train_shape)\n",
    "#     X_test = X_test.reshape(X_test_shape)\n",
    "#     print(X_train.shape, X_test.shape)\n",
    "    \n",
    "    if model_name == \"eegnet\":\n",
    "        X_train = np.swapaxes(X_train, 1, 2)\n",
    "        X_test = np.swapaxes(X_test, 1, 2)\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "    if debug:\n",
    "      print(data_name)\n",
    "      print(\"shape of X_train and Y_train: \" + str(X_train.shape) + \" \" + str(Y_train.shape))\n",
    "      print(\"shape of X_test and Y_test: \" + str(X_test.shape) + \" \" + str(Y_test.shape))\n",
    "\n",
    "    if training:\n",
    "      # create new model\n",
    "      model = create_model(model_name=model_name)\n",
    "      \n",
    "      log_dir = DIRECTORY_PATH + \"/visual/logs/\" + data_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "      tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "      optimizer = Adam(learning_rate=1e-5)\n",
    "      model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "      model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=1000, callbacks=[tensorboard_callback], verbose=0)\n",
    "\n",
    "      Y_hat = model.predict(X_test)\n",
    "      Y_hat = np.argmax(Y_hat, axis=1)\n",
    "      accuracy += accuracy_score(Y_test, Y_hat)\n",
    "      precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "      recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "      f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "      kappa += cohen_kappa_score(Y_test, Y_hat)\n",
    "      Confusion_matrix.append(confusion_matrix(Y_test, Y_hat, labels=range(6)))\n",
    "        \n",
    "      # save model\n",
    "      model.save_weights(DIRECTORY_PATH + \"/visual/models/\" + data_name + \"_\" + str(accuracy_score(Y_test, Y_hat))[:6] + \"/\")\n",
    "    else:\n",
    "      # load pretrained model\n",
    "      model = create_model(model_name=model_name)\n",
    "      model.load_weights(DIRECTORY_PATH + \"/visual/models/\" + \"A09_0.9183/\")\n",
    "      # freeze model\n",
    "      model.trainable = False\n",
    "      optimizer = Adam(learning_rate=1e-5)\n",
    "      model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        \n",
    "      Y_hat = model.predict(X_test)\n",
    "      Y_hat = np.argmax(Y_hat, axis=1)\n",
    "      accuracy += accuracy_score(Y_test, Y_hat)\n",
    "      precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "      recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "      f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "      kappa += cohen_kappa_score(Y_test, Y_hat)\n",
    "      Confusion_matrix.append(confusion_matrix(Y_test, Y_hat, labels=range(6)))\n",
    "\n",
    "  accuracy /= n_splits\n",
    "  precision /= n_splits\n",
    "  recall /= n_splits\n",
    "  f1 /= n_splits\n",
    "  kappa /= n_splits\n",
    "  if debug:\n",
    "    print(\"accuracy: \" + str(accuracy))\n",
    "    print(\"precision: \" + str(precision))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"f1: \" + str(f1))\n",
    "    print(\"kappa: \" + str(kappa))\n",
    "    \n",
    "    if not os.path.exists(DIRECTORY_PATH + \"/visual/pics\"):\n",
    "      os.mkdir(DIRECTORY_PATH + \"/visual/pics\")\n",
    "\n",
    "    for i in range(len(Confusion_matrix)):\n",
    "      disp = ConfusionMatrixDisplay(confusion_matrix=Confusion_matrix[i], display_labels=range(6))\n",
    "      disp.plot()\n",
    "      plt.savefig(DIRECTORY_PATH + \"/visual/pics/\"+data_name+\"_\"+str(i)+'_confusion_matrix.png', bbox_inches='tight')\n",
    "      plt.show()\n",
    "\n",
    "  results[data_name][\"accuracy\"] = accuracy\n",
    "  results[data_name][\"precision\"] = precision\n",
    "  results[data_name][\"recall\"] = recall\n",
    "  results[data_name][\"f1\"] = f1\n",
    "  results[data_name][\"kappa\"] = kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average performance\n",
    "average_accuracy = 0\n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_f1 = 0\n",
    "average_kappa = 0\n",
    "for key, value in results.items():\n",
    "  average_accuracy += value[\"accuracy\"]\n",
    "  average_precision += value[\"precision\"]\n",
    "  average_recall += value[\"recall\"]\n",
    "  average_f1 += value[\"f1\"]\n",
    "  average_kappa += value[\"kappa\"]\n",
    "\n",
    "average_accuracy /= 10\n",
    "average_precision /= 10\n",
    "average_recall /= 10\n",
    "average_f1 /= 10\n",
    "average_kappa /= 10\n",
    "\n",
    "print(\"average accuracy: \" + str(average_accuracy))\n",
    "print(\"average precision: \" + str(average_precision))\n",
    "print(\"average recall: \" + str(average_recall))\n",
    "print(\"average f1: \" + str(average_f1))\n",
    "print(\"average kappa: \" + str(average_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5234199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time computation\n",
    "debug = False\n",
    "model_name = \"default\"\n",
    "warm_up = 10 # initializing memory allocators, and GPU-related initializations \n",
    "\n",
    "data_list = []\n",
    "data_list.append(\"S1\")\n",
    "\n",
    "for data_name in data_list:\n",
    "  X = epochs[data_name][\"epochs\"].get_data()\n",
    "  Y = epochs[data_name][\"labels\"]\n",
    "  X = np.array(X)\n",
    "  Y = np.array(Y)\n",
    "    \n",
    "  Y -= 1\n",
    "  X = np.swapaxes(X, 1, 2)\n",
    "    \n",
    "  if model_name == \"eegnet\":\n",
    "    X = np.swapaxes(X, 1, 2)\n",
    "    X = np.expand_dims(X, axis=-1)\n",
    "    \n",
    "  X_test = np.expand_dims(X[0], axis=0)\n",
    "  Y_test = np.expand_dims(Y[0], axis=0)\n",
    "  print(X_test.shape)\n",
    "    \n",
    "  # load pretrained model\n",
    "  model = create_model(model_name=model_name)\n",
    "  model.load_weights(\"D:/forward and inverse results (new)/visual/default/original EEG/models/S1_0.4720/\")\n",
    "  # freeze model\n",
    "  model.trainable = False\n",
    "  optimizer = Adam(learning_rate=1e-5)\n",
    "  model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "  if model_name == \"default\":\n",
    "    model.build(input_shape=(None, 32, 124))\n",
    "  elif model_name == \"eegnet\":\n",
    "    model.build(input_shape=(None, 124, 32, 1))\n",
    "  print(model.summary())\n",
    "\n",
    "  for i in range(warm_up):\n",
    "    if i == warm_up-1:\n",
    "        start = time.time()\n",
    "    \n",
    "    Y_hat = model.predict(X_test)\n",
    "    \n",
    "    if i == warm_up-1:\n",
    "        end = time.time()\n",
    "        print(\"time used: \", (end - start)*1000, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b747687",
   "metadata": {},
   "source": [
    "# Classification (Reconstruct EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca9e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labels\n",
    "1=Human Body; 2=Human Face; 3=Animal Body; 4=Animal Face; 5=Fruit Vegetable; 6=Inanimate Object\n",
    "\n",
    "channels\n",
    "124\n",
    "\"\"\"\n",
    "\n",
    "results = {\"S1\": {}, \"S2\": {}, \"S3\": {}, \"S4\": {}, \"S5\": {}, \"S6\": {}, \"S7\": {}, \"S8\": {}, \"S9\": {}, \"S10\": {}}\n",
    "debug = True\n",
    "training = True\n",
    "saving_directory = \"/v1-v5 + IT, MT, ST, F reconstruct\"\n",
    "model_name = \"eegnet\"\n",
    "\n",
    "# train model on each subject individually\n",
    "data_list = []\n",
    "for subject in results.keys():\n",
    "  data_list.append(subject)\n",
    "\n",
    "# train model on individual subject\n",
    "# data_list = []\n",
    "# data_list.append(\"S9\")\n",
    "# data_list.append(\"S10\")\n",
    "\n",
    "for data_name in data_list:\n",
    "  # load data from external storage\n",
    "  directory_path = op.join(EXTERNAL_STORAGE_PATH, \"v1-v5 + IT, MT, ST, F region\", \"data\", \"reconstructed eeg\", data_name)\n",
    "  counter = 0\n",
    "  accuracy = 0\n",
    "  precision = 0\n",
    "  recall = 0\n",
    "  f1 = 0\n",
    "  kappa = 0\n",
    "  Confusion_matrix = []\n",
    "\n",
    "  while(counter < n_splits):\n",
    "    counter += 1\n",
    "    X_train = np.load(op.join(directory_path, str(counter)+\"_train_X.npz\"), allow_pickle=True)[\"data\"]\n",
    "    X_test = np.load(op.join(directory_path, str(counter)+\"_test_X.npz\"), allow_pickle=True)[\"data\"]\n",
    "    Y_train = np.load(op.join(directory_path, str(counter)+\"_train_Y.npz\"), allow_pickle=True)[\"data\"]\n",
    "    Y_test = np.load(op.join(directory_path, str(counter)+\"_test_Y.npz\"), allow_pickle=True)[\"data\"]\n",
    "    \n",
    "    Y_train -= 1\n",
    "    Y_test -= 1\n",
    "    \n",
    "    X_train = np.swapaxes(X_train, 1, 2)\n",
    "    X_test = np.swapaxes(X_test, 1, 2)\n",
    "    \n",
    "    if model_name == \"eegnet\":\n",
    "        X_train = np.swapaxes(X_train, 1, 2)\n",
    "        X_test = np.swapaxes(X_test, 1, 2)\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "    if debug:\n",
    "      print(data_name)\n",
    "      print(\"shape of X_train and Y_train: \" + str(X_train.shape) + \" \" + str(Y_train.shape))\n",
    "      print(\"shape of X_test and Y_test: \" + str(X_test.shape) + \" \" + str(Y_test.shape))\n",
    "\n",
    "    if training:\n",
    "      # create new model\n",
    "      model = create_model(model_name=model_name)\n",
    "      \n",
    "      log_dir = DIRECTORY_PATH + saving_directory +\"/logs/\" + data_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "      tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "      optimizer = Adam(learning_rate=1e-5)\n",
    "      model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "      model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=1000, callbacks=[tensorboard_callback], verbose=0)\n",
    "\n",
    "      Y_hat = model.predict(X_test)\n",
    "      Y_hat = np.argmax(Y_hat, axis=1)\n",
    "      accuracy += accuracy_score(Y_test, Y_hat)\n",
    "      precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "      recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "      f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "      kappa += cohen_kappa_score(Y_test, Y_hat)\n",
    "      Confusion_matrix.append(confusion_matrix(Y_test, Y_hat, labels=range(6)))\n",
    "\n",
    "      # save model\n",
    "      model.save_weights(DIRECTORY_PATH + saving_directory + \"/models/\" + data_name + \"_\" + str(accuracy_score(Y_test, Y_hat))[:6] + \"/\")\n",
    "    else:\n",
    "      # load pretrained model\n",
    "      model = create_model(model_name=model_name)\n",
    "      model.load_weights(DIRECTORY_PATH + saving_directory + \"/models/\" + \"A09_0.9183/\")\n",
    "      # freeze model\n",
    "      model.trainable = False\n",
    "      optimizer = Adam(learning_rate=1e-5)\n",
    "      model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        \n",
    "      Y_hat = model.predict(X_test)\n",
    "      Y_hat = np.argmax(Y_hat, axis=1)\n",
    "      accuracy += accuracy_score(Y_test, Y_hat)\n",
    "      precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "      recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "      f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "      kappa += cohen_kappa_score(Y_test, Y_hat)\n",
    "      Confusion_matrix.append(confusion_matrix(Y_test, Y_hat, labels=range(6)))\n",
    "\n",
    "  accuracy /= n_splits\n",
    "  precision /= n_splits\n",
    "  recall /= n_splits\n",
    "  f1 /= n_splits\n",
    "  kappa /= n_splits\n",
    "  if debug:\n",
    "    print(\"accuracy: \" + str(accuracy))\n",
    "    print(\"precision: \" + str(precision))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"f1: \" + str(f1))\n",
    "    print(\"kappa: \" + str(kappa))\n",
    "    \n",
    "    if not os.path.exists(DIRECTORY_PATH + saving_directory + \"/pics\"):\n",
    "      os.mkdir(DIRECTORY_PATH + saving_directory + \"/pics\")\n",
    "\n",
    "    for i in range(len(Confusion_matrix)):\n",
    "      disp = ConfusionMatrixDisplay(confusion_matrix=Confusion_matrix[i], display_labels=range(6))\n",
    "      disp.plot()\n",
    "      plt.savefig(DIRECTORY_PATH + saving_directory + \"/pics/\"+data_name+\"_\"+str(i)+'_confusion_matrix.png', bbox_inches='tight')\n",
    "      plt.show()\n",
    "\n",
    "  results[data_name][\"accuracy\"] = accuracy\n",
    "  results[data_name][\"precision\"] = precision\n",
    "  results[data_name][\"recall\"] = recall\n",
    "  results[data_name][\"f1\"] = f1\n",
    "  results[data_name][\"kappa\"] = kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average performance\n",
    "average_accuracy = 0\n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_f1 = 0\n",
    "average_kappa = 0\n",
    "for key, value in results.items():\n",
    "  average_accuracy += value[\"accuracy\"]\n",
    "  average_precision += value[\"precision\"]\n",
    "  average_recall += value[\"recall\"]\n",
    "  average_f1 += value[\"f1\"]\n",
    "  average_kappa += value[\"kappa\"]\n",
    "\n",
    "average_accuracy /= 10\n",
    "average_precision /= 10\n",
    "average_recall /= 10\n",
    "average_f1 /= 10\n",
    "average_kappa /= 10\n",
    "\n",
    "print(\"average accuracy: \" + str(average_accuracy))\n",
    "print(\"average precision: \" + str(average_precision))\n",
    "print(\"average recall: \" + str(average_recall))\n",
    "print(\"average f1: \" + str(average_f1))\n",
    "print(\"average kappa: \" + str(average_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time computation\n",
    "debug = False\n",
    "model_name = \"eegnet\"\n",
    "warm_up = 10 # initializing memory allocators, and GPU-related initializations \n",
    "\n",
    "data_list = []\n",
    "data_list.append(\"S1\")\n",
    "\n",
    "information = get_inverse_and_forward_information(epochs)\n",
    "print(information)\n",
    "leadfield = information[\"leadfield\"]\n",
    "inverse_operator = information[\"inverse_operator\"]\n",
    "my_left_points = information[\"my_left_points\"]\n",
    "my_right_points = information[\"my_right_points\"]\n",
    "info = epochs[\"S1\"][\"epochs\"].info\n",
    "\n",
    "for data_name in data_list:\n",
    "  X = epochs[data_name][\"epochs\"].get_data()\n",
    "  Y = epochs[data_name][\"labels\"]\n",
    "  X = np.array(X)\n",
    "  Y = np.array(Y)\n",
    "    \n",
    "  Y -= 1\n",
    "  X_test = np.expand_dims(X[0], axis=0)\n",
    "  Y_test = np.expand_dims(Y[0], axis=0)\n",
    "  print(X_test.shape)\n",
    "    \n",
    "  # load pretrained model\n",
    "  model = create_model(model_name=model_name)\n",
    "  model.load_weights(\"D:/forward and inverse results (new)/visual/eegnet/v1-v5 reconstruct/models/S1_0.4489/\")\n",
    "  # freeze model\n",
    "  model.trainable = False\n",
    "  optimizer = Adam(learning_rate=1e-5)\n",
    "  model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "  if model_name == \"default\":\n",
    "    model.build(input_shape=(None, 32, 124))\n",
    "  elif model_name == \"eegnet\":\n",
    "    model.build(input_shape=(None, 124, 32, 1))\n",
    "\n",
    "  for i in range(warm_up):\n",
    "    if i == warm_up-1:\n",
    "        start = time.time()\n",
    "        \n",
    "    X_epochs = mne.EpochsArray(X_test, info, verbose=False)\n",
    "    method = \"sLORETA\"\n",
    "    snr = 3.\n",
    "    lambda2 = 1. / snr ** 2\n",
    "    stc_test = apply_inverse_epochs(X_epochs, inverse_operator, lambda2,\n",
    "                                  method=method, pick_ori=\"normal\", verbose=debug)\n",
    "    \n",
    "    # slice reconstructed eeg data\n",
    "    reconstructed_eeg_data = []\n",
    "    for source in stc_test:\n",
    "        visual_source = np.zeros_like(source.data)\n",
    "        visual_source[:len(source.vertices[0])][my_left_points] = source.data[:len(source.vertices[0])][my_left_points]\n",
    "        visual_source[-len(source.vertices[1]):][my_right_points] = source.data[-len(source.vertices[1]):][my_right_points]\n",
    "        visual_eeg = np.dot(leadfield, visual_source)\n",
    "        reconstructed_eeg_data.append(visual_eeg)\n",
    "    reconstructed_eeg_data = np.array(reconstructed_eeg_data)\n",
    "    print(reconstructed_eeg_data.shape)\n",
    "    \n",
    "    X_time = np.swapaxes(reconstructed_eeg_data, 1, 2)\n",
    "    \n",
    "    if model_name == \"eegnet\":\n",
    "      X_time = np.swapaxes(X_time, 1, 2)\n",
    "      X_time = np.expand_dims(X_time, axis=-1)\n",
    "    \n",
    "    Y_hat = model.predict(X_time)\n",
    "    \n",
    "    if i == warm_up-1:\n",
    "        end = time.time()\n",
    "        print(\"time used: \", (end - start)*1000, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775aecab",
   "metadata": {},
   "source": [
    "# Classification (Auto-select Source Activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ce700",
   "metadata": {},
   "outputs": [],
   "source": [
    "information = get_inverse_and_forward_information(epochs)\n",
    "print(information)\n",
    "\n",
    "print(information[\"leadfield\"][:, :len(information[\"left_vertices\"])][:, information[\"my_left_points\"]].shape)\n",
    "print(information[\"leadfield\"][:, -len(information[\"right_vertices\"]):][:, information[\"my_right_points\"]].shape)\n",
    "forward_matrix = np.concatenate((information[\"leadfield\"][:, :len(information[\"left_vertices\"])][:, information[\"my_left_points\"]], \n",
    "                          information[\"leadfield\"][:, -len(information[\"right_vertices\"]):][:, information[\"my_right_points\"]]),\n",
    "                          axis = 1)\n",
    "print(forward_matrix.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679acf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labels\n",
    "1=Human Body; 2=Human Face; 3=Animal Body; 4=Animal Face; 5=Fruit Vegetable; 6=Inanimate Object\n",
    "\n",
    "channels\n",
    "124\n",
    "\"\"\"\n",
    "\n",
    "results = {\"S1\": {}, \"S2\": {}, \"S3\": {}, \"S4\": {}, \"S5\": {}, \"S6\": {}, \"S7\": {}, \"S8\": {}, \"S9\": {}, \"S10\": {}}\n",
    "debug = True\n",
    "training = True\n",
    "random_select = False\n",
    "use_mask = True\n",
    "saving_directory = \"/v1-v5 source selection initialize mask 1\"\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "model_name = \"eegnet\"\n",
    "\n",
    "# train model on each subject individually\n",
    "data_list = []\n",
    "for subject in results.keys():\n",
    "  data_list.append(subject)\n",
    "\n",
    "# train model on individual subject\n",
    "# data_list = []\n",
    "# data_list.append(\"S2\")\n",
    "\n",
    "for data_name in data_list:\n",
    "  # load data from external storage\n",
    "  directory_path = op.join(EXTERNAL_STORAGE_PATH, \"v1-v5 region\", \"data\", \"source activity\", data_name)\n",
    "  counter = 0\n",
    "  accuracy = 0\n",
    "  precision = 0\n",
    "  recall = 0\n",
    "  f1 = 0\n",
    "  kappa = 0\n",
    "  Confusion_matrix = []\n",
    "\n",
    "  while(counter < n_splits):\n",
    "        \n",
    "    counter += 1\n",
    "    X_train = np.load(op.join(directory_path, str(counter)+\"_train_X.npz\"), allow_pickle=True)[\"data\"]\n",
    "    X_test = np.load(op.join(directory_path, str(counter)+\"_test_X.npz\"), allow_pickle=True)[\"data\"]\n",
    "    Y_train = np.load(op.join(directory_path, str(counter)+\"_train_Y.npz\"), allow_pickle=True)[\"data\"]\n",
    "    Y_test = np.load(op.join(directory_path, str(counter)+\"_test_Y.npz\"), allow_pickle=True)[\"data\"]\n",
    "    \n",
    "    Y_train -= 1\n",
    "    Y_test -= 1\n",
    "    \n",
    "    X_train_batches = np.array_split(X_train, X_train.shape[0] // batch_size + 1)\n",
    "    Y_train_batches = np.array_split(Y_train, X_train.shape[0] // batch_size + 1)\n",
    "    X_test_batches = np.array_split(X_test, X_test.shape[0] // batch_size + 1)\n",
    "    Y_test_batches = np.array_split(Y_test, Y_test.shape[0] // batch_size + 1)\n",
    "\n",
    "    if debug:\n",
    "      print(data_name)\n",
    "      print(\"shape of X_train and Y_train: \" + str(X_train.shape) + \" \" + str(Y_train.shape))\n",
    "      print(\"shape of X_test and Y_test: \" + str(X_test.shape) + \" \" + str(Y_test.shape))\n",
    "\n",
    "    if training:\n",
    "      # create new model\n",
    "      model = AutoSelect(forward_matrix, random_select, use_mask, model_name)\n",
    "      \n",
    "      log_dir = DIRECTORY_PATH + saving_directory +\"/logs/\" + data_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "      optimizer = Adam(learning_rate=1e-5)\n",
    "      loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "      train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\n",
    "      test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\n",
    "      train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "      test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "      train_log_writer = tf.summary.create_file_writer(log_dir+\"/train\")\n",
    "      test_log_writer = tf.summary.create_file_writer(log_dir+\"/test\")\n",
    "    \n",
    "      @tf.function\n",
    "      def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(x, training=True)\n",
    "            loss_value = loss_fn(y, prediction)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y, prediction)\n",
    "        train_loss.update_state(loss_value)\n",
    "        return loss_value\n",
    "\n",
    "      @tf.function\n",
    "      def test_step(x, y):\n",
    "        test_prediction = model(x, training=False)\n",
    "        loss_value = loss_fn(y, test_prediction)\n",
    "        test_acc_metric.update_state(y, test_prediction)\n",
    "        test_loss.update_state(loss_value)\n",
    "        \n",
    "      for epoch in range(epochs):\n",
    "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_index in range(len(X_train_batches)):\n",
    "            loss_value = train_step(X_train_batches[batch_index], Y_train_batches[batch_index])\n",
    "        with train_log_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_acc_metric.result(), step=epoch)\n",
    "        #print(\"Training loss at epoch %d: %.4f\" % (epoch, float(loss_value)))\n",
    "        train_acc = train_acc_metric.result()\n",
    "        #print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "        train_acc_metric.reset_states()\n",
    "        train_loss.reset_states()\n",
    "\n",
    "        for batch_index in range(len(X_test_batches)):\n",
    "            test_step(X_test_batches[batch_index], Y_test_batches[batch_index])\n",
    "        with test_log_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_acc_metric.result(), step=epoch)\n",
    "        test_acc = test_acc_metric.result()\n",
    "        test_acc_metric.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        #print(\"Test acc: %.4f\" % (float(test_acc),))\n",
    "        #print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "\n",
    "      Y_hat = model(X_test, training=False)\n",
    "      Y_hat = np.argmax(Y_hat, axis=1)\n",
    "      accuracy += accuracy_score(Y_test, Y_hat)\n",
    "      precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "      recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "      f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "      kappa += cohen_kappa_score(Y_test, Y_hat)\n",
    "      Confusion_matrix.append(confusion_matrix(Y_test, Y_hat, labels=range(6)))\n",
    "\n",
    "      # save model\n",
    "      model.save_weights(DIRECTORY_PATH + saving_directory + \"/models/\" + data_name + \"_\" + str(accuracy_score(Y_test, Y_hat))[:6] + \"/\")\n",
    "    else:\n",
    "      # load pretrained model\n",
    "      model = AutoSelect(forward_matrix, random_select, use_mask, model_name)\n",
    "      model.load_weights(DIRECTORY_PATH + saving_directory + \"/models/\" + \"A09_0.9183/\")\n",
    "      # freeze model\n",
    "      model.trainable = False\n",
    "      optimizer = Adam(learning_rate=1e-5)\n",
    "      model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        \n",
    "      Y_hat = model(X_test, training=False)\n",
    "      Y_hat = np.argmax(Y_hat, axis=1)\n",
    "      accuracy += accuracy_score(Y_test, Y_hat)\n",
    "      precision += precision_score(Y_test, Y_hat, average=\"macro\")\n",
    "      recall += recall_score(Y_test, Y_hat, average=\"macro\")\n",
    "      f1 += f1_score(Y_test, Y_hat, average=\"macro\")\n",
    "      kappa += cohen_kappa_score(Y_test, Y_hat)\n",
    "      Confusion_matrix.append(confusion_matrix(Y_test, Y_hat, labels=range(6)))\n",
    "\n",
    "  accuracy /= n_splits\n",
    "  precision /= n_splits\n",
    "  recall /= n_splits\n",
    "  f1 /= n_splits\n",
    "  kappa /= n_splits\n",
    "  if debug:\n",
    "    print(\"accuracy: \" + str(accuracy))\n",
    "    print(\"precision: \" + str(precision))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"f1: \" + str(f1))\n",
    "    print(\"kappa: \" + str(kappa))\n",
    "    \n",
    "    if not os.path.exists(DIRECTORY_PATH + saving_directory + \"/pics\"):\n",
    "      os.mkdir(DIRECTORY_PATH + saving_directory + \"/pics\")\n",
    "\n",
    "    for i in range(len(Confusion_matrix)):\n",
    "      disp = ConfusionMatrixDisplay(confusion_matrix=Confusion_matrix[i], display_labels=range(6))\n",
    "      disp.plot()\n",
    "      plt.savefig(DIRECTORY_PATH + saving_directory + \"/pics/\"+data_name+\"_\"+str(i)+'_confusion_matrix.png', bbox_inches='tight')\n",
    "      plt.show()\n",
    "\n",
    "  results[data_name][\"accuracy\"] = accuracy\n",
    "  results[data_name][\"precision\"] = precision\n",
    "  results[data_name][\"recall\"] = recall\n",
    "  results[data_name][\"f1\"] = f1\n",
    "  results[data_name][\"kappa\"] = kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average performance\n",
    "average_accuracy = 0\n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_f1 = 0\n",
    "average_kappa = 0\n",
    "for key, value in results.items():\n",
    "  average_accuracy += value[\"accuracy\"]\n",
    "  average_precision += value[\"precision\"]\n",
    "  average_recall += value[\"recall\"]\n",
    "  average_f1 += value[\"f1\"]\n",
    "  average_kappa += value[\"kappa\"]\n",
    "\n",
    "average_accuracy /= 10\n",
    "average_precision /= 10\n",
    "average_recall /= 10\n",
    "average_f1 /= 10\n",
    "average_kappa /= 10\n",
    "\n",
    "print(\"average accuracy: \" + str(average_accuracy))\n",
    "print(\"average precision: \" + str(average_precision))\n",
    "print(\"average recall: \" + str(average_recall))\n",
    "print(\"average f1: \" + str(average_f1))\n",
    "print(\"average kappa: \" + str(average_kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time computation\n",
    "debug = False\n",
    "random_select = False\n",
    "use_mask = True\n",
    "model_name = \"eegnet\"\n",
    "warm_up = 10 # initializing memory allocators, and GPU-related initializations \n",
    "\n",
    "data_list = []\n",
    "data_list.append(\"S1\")\n",
    "\n",
    "information = get_inverse_and_forward_information(epochs)\n",
    "print(information)\n",
    "print(information[\"leadfield\"][:, :len(information[\"left_vertices\"])][:, information[\"my_left_points\"]].shape)\n",
    "print(information[\"leadfield\"][:, -len(information[\"right_vertices\"]):][:, information[\"my_right_points\"]].shape)\n",
    "forward_matrix = np.concatenate((information[\"leadfield\"][:, :len(information[\"left_vertices\"])][:, information[\"my_left_points\"]], \n",
    "                          information[\"leadfield\"][:, -len(information[\"right_vertices\"]):][:, information[\"my_right_points\"]]),\n",
    "                          axis = 1)\n",
    "print(forward_matrix.shape)\n",
    "inverse_operator = information[\"inverse_operator\"]\n",
    "my_left_points = information[\"my_left_points\"]\n",
    "my_right_points = information[\"my_right_points\"]\n",
    "info = epochs[\"S1\"][\"epochs\"].info\n",
    "\n",
    "for data_name in data_list:\n",
    "  X = epochs[data_name][\"epochs\"].get_data()\n",
    "  Y = epochs[data_name][\"labels\"]\n",
    "  X = np.array(X)\n",
    "  Y = np.array(Y)\n",
    "    \n",
    "  Y -= 1\n",
    "  X_test = np.expand_dims(X[0], axis=0)\n",
    "  Y_test = np.expand_dims(Y[0], axis=0)\n",
    "  print(X_test.shape)\n",
    "    \n",
    "  # load pretrained model\n",
    "  model = AutoSelect(forward_matrix, random_select, use_mask, model_name)\n",
    "  model.load_weights(\"D:/forward and inverse results (new)/visual/eegnet/v1-v5+IT,MT,ST,F source selection Mask Initialize 1/models/S1_0.4720/\")\n",
    "  # freeze model\n",
    "  model.trainable = False\n",
    "  optimizer = Adam(learning_rate=1e-5)\n",
    "  model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "  model.build(input_shape=(None, forward_matrix.shape[1], 32))\n",
    "\n",
    "  for i in range(warm_up):\n",
    "    if i == warm_up-1:\n",
    "        start = time.time()\n",
    "        \n",
    "    X_epochs = mne.EpochsArray(X_test, info, verbose=False)\n",
    "    method = \"sLORETA\"\n",
    "    snr = 3.\n",
    "    lambda2 = 1. / snr ** 2\n",
    "    stc_test = apply_inverse_epochs(X_epochs, inverse_operator, lambda2,\n",
    "                                  method=method, pick_ori=\"normal\", verbose=debug)\n",
    "    \n",
    "    # slice source activity data\n",
    "    left_hemi_data = []\n",
    "    right_hemi_data = []\n",
    "    for source in stc_test:\n",
    "        left_hemi_data.append(source.data[:len(source.vertices[0])][my_left_points])\n",
    "        right_hemi_data.append(source.data[-len(source.vertices[1]):][my_right_points])\n",
    "    left_hemi_data = np.array(left_hemi_data)\n",
    "    right_hemi_data = np.array(right_hemi_data)\n",
    "    \n",
    "    X_time = np.append(left_hemi_data, right_hemi_data, axis=1)\n",
    "    print(X_time.shape)\n",
    "    \n",
    "    Y_hat = model(X_time, training=False)\n",
    "    \n",
    "    if i == warm_up-1:\n",
    "        end = time.time()\n",
    "        print(\"time used: \", (end - start)*1000, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6ff64",
   "metadata": {},
   "source": [
    "# Visualizing Mask and Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a1b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoSelect(forward_matrix, False, False, \"default\")\n",
    "model.build(input_shape=(None, 3240, 32))\n",
    "#print(model.summary())\n",
    "load_model_directory = \"v1-v5 source selection initialize mask 1/models/\"\n",
    "load_model_subject = \"S6_0.6470/\"\n",
    "\n",
    "model.load_weights(\"D:\" + \"/forward and inverse results (new)/visual/default/\" + load_model_directory + load_model_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in model.get_weights():\n",
    "    print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cc76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mni_lh = mne.vertex_to_mni(information[\"left_vertices\"], 0, mne_subject)\n",
    "print(mni_lh.shape)\n",
    "mni_rh = mne.vertex_to_mni(information[\"right_vertices\"], 1, mne_subject)\n",
    "print(mni_rh.shape)\n",
    "\n",
    "mni_left_points = mni_lh[information[\"my_left_points\"]]\n",
    "print(mni_left_points.shape)\n",
    "mni_right_points = mni_rh[information[\"my_right_points\"]]\n",
    "print(mni_right_points.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(mni_lh[:, 0], mni_lh[:, 1], mni_lh[:, 2], s=15, marker='|')\n",
    "ax.scatter(mni_rh[:, 0], mni_rh[:, 1], mni_rh[:, 2], s=15, marker='_')\n",
    "ax.scatter(mni_left_points[:, 0], mni_left_points[:, 1], mni_left_points[:, 2], s=15, marker='o')\n",
    "ax.scatter(mni_right_points[:, 0], mni_right_points[:, 1], mni_right_points[:, 2], s=15, marker='^')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004667d2",
   "metadata": {},
   "source": [
    "## Mask Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614338d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mask\n",
    "#np.sum(model.get_weights()[-1] >= 1)\n",
    "\n",
    "for pts in model.get_weights()[-1]:\n",
    "    print(pts)\n",
    "print(np.max(model.get_weights()[-1]))\n",
    "print(np.min(model.get_weights()[-1]))\n",
    "print(np.mean(model.get_weights()[-1]))\n",
    "print(np.std(model.get_weights()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_weight = np.zeros((information[\"my_left_points\"].shape))\n",
    "right_weight =  np.zeros((information[\"my_right_points\"].shape))\n",
    "left_weight[information[\"my_left_points\"]] = model.get_weights()[-1].reshape(-1)[:np.sum(information[\"my_left_points\"])]\n",
    "right_weight[information[\"my_right_points\"]] = model.get_weights()[-1].reshape(-1)[np.sum(information[\"my_left_points\"]):]\n",
    "\n",
    "total_weight = np.append(left_weight, right_weight, axis=0)\n",
    "print(total_weight)\n",
    "print(total_weight.shape)\n",
    "\n",
    "# binary weights\n",
    "total_weight = (total_weight >= 1).astype(int)\n",
    "print(total_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a93ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_tree = KDTree(mm_coords.reshape(-1, 3))\n",
    "final_weight = np.zeros(mm_coords.reshape(-1, 3).shape)\n",
    "\n",
    "max_points = 0\n",
    "for i, vertex_i in enumerate(vertices_tree.query_ball_point(np.append(mni_lh, mni_rh, axis=0), 2)):\n",
    "    if vertex_i != []:\n",
    "        if np.max(vertex_i) > max_points:\n",
    "            max_points = np.max(vertex_i)\n",
    "        #print(mm_coords.reshape(-1, 3)[np.max(vertex_i)])\n",
    "        #print(np.append(mni_lh, mni_rh, axis=0)[i])\n",
    "        \n",
    "        # fill all\n",
    "        for vertex_j in vertex_i:\n",
    "            final_weight[vertex_j] = total_weight[i]\n",
    "        # fill biggest index\n",
    "        #final_weight[np.max(vertex_i)] = total_weight[i]\n",
    "        #print(vertex_i)\n",
    "print(max_points)\n",
    "\n",
    "final_weight = final_weight.reshape(mm_coords.shape)[:, :, :, 0]\n",
    "\n",
    "visualization_mask = Nifti1Image(final_weight, ch2_img.affine, ch2_img.header)\n",
    "nib.save(visualization_mask, os.path.join('C:/Users/ivanlim/Desktop/EEG-forward-and-inverse', 'visualization_mask.nii.gz'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_mask_with_shape = Nifti1Image(np.asanyarray(final_weight), ch2_img.affine, ch2_img.header)\n",
    "nib.save(visualization_mask_with_shape, os.path.join('C:/Users/ivanlim/Desktop/EEG-forward-and-inverse', 'visualization_mask_with_shape.nii.gz')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725ec2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(\"C:/Users/ivanlim/Desktop/EEG-forward-and-inverse/visualization_mask_with_shape.nii.gz\", display_mode='xz', threshold=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5a082",
   "metadata": {},
   "source": [
    "# Statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tensorboard(path, scalars):\n",
    "    \"\"\"returns a dictionary of pandas dataframes for each requested scalar\"\"\"\n",
    "    ea = event_accumulator.EventAccumulator(\n",
    "        path,\n",
    "        size_guidance={event_accumulator.SCALARS: 0},\n",
    "    )\n",
    "    _absorb_print = ea.Reload()\n",
    "    #print(ea.Tags())\n",
    "    # make sure the scalars are in the event accumulator tags\n",
    "    assert all(\n",
    "        s in ea.Tags()['tensors'] for s in scalars\n",
    "    ), \"some scalars were not found in the event accumulator\"\n",
    "    return {k: pd.DataFrame(ea.Tensors(k)) for k in scalars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c920f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method_path = \"D:/forward and inverse results (new)/visual/default\"\n",
    "accuracy_dict = {}\n",
    "\n",
    "for method in [\"original EEG\", \"v1-v5 reconstruct\", \"v1-v5 + IT, MT, ST, F reconstruct\", \n",
    "               \"v1-v5 source selection dense + dropout 0.1\", \"v1-v5 source selection initialize mask 1\",\n",
    "               \"v1-v5 source selection mask initialize 0.5-1.5\", \"v1-v5+IT,MT,ST,F source selection Mask Initialize 1\",\n",
    "               \"v1-v5+IT,MT,ST,F source selection Mask initialize 0.5-1.5\"]:\n",
    "    logs_path = os.path.join(method_path, method, \"logs\")\n",
    "    if not accuracy_dict.get(method):\n",
    "        accuracy_dict[method] = {}\n",
    "    for subject in os.listdir(logs_path):\n",
    "        if not accuracy_dict[method].get(subject):\n",
    "            accuracy_dict[method][subject] = {}\n",
    "        subject_path = os.path.join(logs_path, subject)\n",
    "        for time in os.listdir(subject_path):\n",
    "            if method == \"original EEG\" or method == \"v1-v5 reconstruct\" or method == \"v1-v5 + IT, MT, ST, F reconstruct\" or method == \"v1-v5 source selection initialize mask 1\":\n",
    "                validation_path = os.path.join(subject_path, time, \"validation\")\n",
    "            elif method == \"v1-v5 source selection mask initialize 0.5-1.5\":\n",
    "                validation_path = os.path.join(subject_path, time)\n",
    "            else:\n",
    "                validation_path = os.path.join(subject_path, time, \"test\")\n",
    "            tensorboard_logs = os.path.join(validation_path, os.listdir(validation_path)[0])\n",
    "            if method == \"original EEG\" or method == \"v1-v5 reconstruct\" or method == \"v1-v5 + IT, MT, ST, F reconstruct\" or method == \"v1-v5 source selection initialize mask 1\":\n",
    "                df = parse_tensorboard(tensorboard_logs, [\"epoch_loss\", \"epoch_accuracy\"])\n",
    "                last_test_accuracy = tf.constant(tf.make_ndarray(df[\"epoch_accuracy\"][\"tensor_proto\"][len(df[\"epoch_accuracy\"][\"tensor_proto\"])-1]))\n",
    "            elif method == \"v1-v5 source selection mask initialize 0.5-1.5\":\n",
    "                df = parse_tensorboard(tensorboard_logs, [\"testing loss\", \"testing accuracy\"])\n",
    "                last_test_accuracy = tf.constant(tf.make_ndarray(df[\"testing accuracy\"][\"tensor_proto\"][len(df[\"testing accuracy\"][\"tensor_proto\"])-1]))\n",
    "            else:\n",
    "                df = parse_tensorboard(tensorboard_logs, [\"loss\", \"accuracy\"])\n",
    "                last_test_accuracy = tf.constant(tf.make_ndarray(df[\"accuracy\"][\"tensor_proto\"][len(df[\"accuracy\"][\"tensor_proto\"])-1]))\n",
    "            #print(subject, time)\n",
    "            accuracy_dict[method][subject][time] = last_test_accuracy.numpy()\n",
    "            \n",
    "accuracy_mean_std = {}\n",
    "for method in accuracy_dict.keys():\n",
    "    accuracy_mean_std[method] = {}\n",
    "    for subject in accuracy_dict[method].keys():\n",
    "        accuracy_time = list(accuracy_dict[method][subject].values())\n",
    "        mean = np.mean(accuracy_time)\n",
    "        std = np.std(accuracy_time)\n",
    "        accuracy_mean_std[method][subject] = {}\n",
    "        accuracy_mean_std[method][subject][\"mean\"] = mean\n",
    "        accuracy_mean_std[method][subject][\"std\"] = std\n",
    "        #print(method, subject, mean)\n",
    "        \n",
    "subject_list = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"S10\"]\n",
    "test_samples = [1038, 1037, 1037, 1037, 1037, 1037, 1038, 1037, 1037, 1037]\n",
    "t_test_results = {}\n",
    "\n",
    "for i, subject in enumerate(subject_list):\n",
    "    t_test_results[subject] = {}\n",
    "    count = 0\n",
    "    for method in accuracy_mean_std.keys():\n",
    "        if method == \"original EEG\" or method == \"all motor attention with dropout 0.5\":\n",
    "            continue\n",
    "        mean_1 = accuracy_mean_std[\"original EEG\"][subject][\"mean\"]\n",
    "        mean_2 = accuracy_mean_std[method][subject][\"mean\"]\n",
    "        std_1 = accuracy_mean_std[\"original EEG\"][subject][\"std\"]\n",
    "        std_2 = accuracy_mean_std[method][subject][\"std\"]\n",
    "        n = test_samples[i]\n",
    "        \n",
    "        df = n+n-2\n",
    "        s_p = np.sqrt(((n-1)*(std_1**2)+(n-1)*(std_2**2))/(n+n-2))\n",
    "        t = (mean_1-mean_2) / (s_p*np.sqrt(1/n+1/n))\n",
    "        p_value = stats.t.sf(np.abs(t), df)*2\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            count += 1\n",
    "            print(subject, method, mean_2)\n",
    "        #print(t, df, p_value)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_path = \"D:/forward and inverse results (new)/visual/eegnet\"\n",
    "accuracy_dict = {}\n",
    "\n",
    "for method in [\"original EEG\", \"v1-v5 reconstruct\", \"v1-v5 + IT, MT, ST, F reconstruct\", \n",
    "               \"v1-v5 source selection dense + dropout 0.1\", \"v1-v5 source selection initialize mask 1\",\n",
    "               \"v1-v5 source selection initialize mask 0.5 - 1.5\", \"v1-v5+IT,MT,ST,F source selection Mask Initialize 1\",\n",
    "               \"v1-v5+IT,MT,ST,F source selection Mask initialize 0.5-1.5\"]:\n",
    "    logs_path = os.path.join(method_path, method, \"logs\")\n",
    "    if not accuracy_dict.get(method):\n",
    "        accuracy_dict[method] = {}\n",
    "    for subject in os.listdir(logs_path):\n",
    "        if not accuracy_dict[method].get(subject):\n",
    "            accuracy_dict[method][subject] = {}\n",
    "        subject_path = os.path.join(logs_path, subject)\n",
    "        for time in os.listdir(subject_path):\n",
    "            if method == \"original EEG\" or method == \"v1-v5 reconstruct\" or method == \"v1-v5 + IT, MT, ST, F reconstruct\":\n",
    "                validation_path = os.path.join(subject_path, time, \"validation\")\n",
    "            else:\n",
    "                validation_path = os.path.join(subject_path, time, \"test\")\n",
    "            tensorboard_logs = os.path.join(validation_path, os.listdir(validation_path)[0])\n",
    "            if method == \"original EEG\" or method == \"v1-v5 reconstruct\" or method == \"v1-v5 + IT, MT, ST, F reconstruct\":\n",
    "                df = parse_tensorboard(tensorboard_logs, [\"epoch_loss\", \"epoch_accuracy\"])\n",
    "                last_test_accuracy = tf.constant(tf.make_ndarray(df[\"epoch_accuracy\"][\"tensor_proto\"][len(df[\"epoch_accuracy\"][\"tensor_proto\"])-1]))\n",
    "            else:\n",
    "                df = parse_tensorboard(tensorboard_logs, [\"loss\", \"accuracy\"])\n",
    "                last_test_accuracy = tf.constant(tf.make_ndarray(df[\"accuracy\"][\"tensor_proto\"][len(df[\"accuracy\"][\"tensor_proto\"])-1]))\n",
    "            #print(subject, time)\n",
    "            accuracy_dict[method][subject][time] = last_test_accuracy.numpy()\n",
    "            \n",
    "accuracy_mean_std = {}\n",
    "for method in accuracy_dict.keys():\n",
    "    accuracy_mean_std[method] = {}\n",
    "    for subject in accuracy_dict[method].keys():\n",
    "        accuracy_time = list(accuracy_dict[method][subject].values())\n",
    "        mean = np.mean(accuracy_time)\n",
    "        std = np.std(accuracy_time)\n",
    "        accuracy_mean_std[method][subject] = {}\n",
    "        accuracy_mean_std[method][subject][\"mean\"] = mean\n",
    "        accuracy_mean_std[method][subject][\"std\"] = std\n",
    "        #print(method, subject, mean)\n",
    "        \n",
    "subject_list = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"S10\"]\n",
    "test_samples = [1038, 1037, 1037, 1037, 1037, 1037, 1038, 1037, 1037, 1037]\n",
    "t_test_results = {}\n",
    "\n",
    "for i, subject in enumerate(subject_list):\n",
    "    t_test_results[subject] = {}\n",
    "    count = 0\n",
    "    for method in accuracy_mean_std.keys():\n",
    "        if method == \"original EEG\" or method == \"all motor attention with dropout 0.5\":\n",
    "            continue\n",
    "        mean_1 = accuracy_mean_std[\"original EEG\"][subject][\"mean\"]\n",
    "        mean_2 = accuracy_mean_std[method][subject][\"mean\"]\n",
    "        std_1 = accuracy_mean_std[\"original EEG\"][subject][\"std\"]\n",
    "        std_2 = accuracy_mean_std[method][subject][\"std\"]\n",
    "        n = test_samples[i]\n",
    "        \n",
    "        df = n+n-2\n",
    "        s_p = np.sqrt(((n-1)*(std_1**2)+(n-1)*(std_2**2))/(n+n-2))\n",
    "        t = (mean_1-mean_2) / (s_p*np.sqrt(1/n+1/n))\n",
    "        p_value = stats.t.sf(np.abs(t), df)*2\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            count += 1\n",
    "            print(subject, method, mean_2)\n",
    "        #print(t, df, p_value)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb01f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
